#!/usr/bin/env python3
"""
NotifyBot - Enhanced Email Campaign Automation System
=====================================================

A comprehensive Python-based email automation system designed for sending personalized 
batch emails with advanced filtering, template substitution, dual-mode operation, and 
enhanced field validation with priority-based inventory management.

OVERVIEW
--------
NotifyBot supports two primary operating modes with enhanced CSV integration:
- SINGLE MODE: Send one email to multiple recipients (traditional bulk email)
- MULTI MODE: Send multiple personalized emails based on CSV filter conditions

NEW IN THIS VERSION
-------------------
üîß Enhanced Field Validation System:
   ‚Ä¢ Priority-based validation with local and global inventory support
   ‚Ä¢ Improved field name validation with whitespace handling
   ‚Ä¢ Dynamic field support for runtime table generation
   ‚Ä¢ Better error reporting and field suggestion system

üìä Advanced Table Generation:
   ‚Ä¢ table-columns.txt support for defining table structure
   ‚Ä¢ Multiple table formats: styled, simple, CSV-style
   ‚Ä¢ Dynamic table headers and content generation
   ‚Ä¢ Backward compatibility with legacy dynamic_table field

üõ°Ô∏è Improved Safety & Validation:
   ‚Ä¢ Enhanced attachment size limit checking (15MB default)
   ‚Ä¢ Better recipient source validation and logging
   ‚Ä¢ Improved email format validation with sendmail compatibility
   ‚Ä¢ Enhanced error handling and user guidance

KEY FEATURES
------------
‚ú® Dual Mode Operation:
   ‚Ä¢ Single Mode: Traditional bulk email to multiple recipients
   ‚Ä¢ Multi Mode: Personalized emails with CSV-based filtering and template substitution

üìä Advanced CSV Integration:
   ‚Ä¢ Dynamic recipient filtering using PromQL-style syntax
   ‚Ä¢ Template placeholder substitution from CSV data  
   ‚Ä¢ Support for local and global CSV inventories with priority-based validation
   ‚Ä¢ Dynamic table generation from filtered CSV rows with configurable columns

üéØ Flexible Recipient Management:
   ‚Ä¢ Multiple recipient sources (TO, CC, BCC, filters, additional lists)
   ‚Ä¢ Automatic email deduplication and validation
   ‚Ä¢ Support for semicolon-separated email lists
   ‚Ä¢ Batch processing with configurable sizes and delays

üìß Rich Email Features:
   ‚Ä¢ HTML email support with embedded images
   ‚Ä¢ Global signature integration from /notifybot/signature.html
   ‚Ä¢ File attachments with size limit validation (15MB default)
   ‚Ä¢ Proper MIME multipart message construction

üõ°Ô∏è Safety & Testing:
   ‚Ä¢ Dry-run mode sends DRAFT emails to approvers only
   ‚Ä¢ Comprehensive field validation against CSV inventories with priority system
   ‚Ä¢ Size limits and email format validation
   ‚Ä¢ Detailed logging with CSV format for audit trails

üîß Enterprise-Ready:
   ‚Ä¢ Priority-based field validation system
   ‚Ä¢ Sendmail integration for reliable delivery
   ‚Ä¢ Configurable batch processing and rate limiting
   ‚Ä¢ Comprehensive error handling and recovery

DIRECTORY STRUCTURE
-------------------
/notifybot/                          # Root directory
‚îú‚îÄ‚îÄ basefolder/                      # Base folder for all campaigns
‚îÇ   ‚îî‚îÄ‚îÄ <campaign-name>/             # Individual campaign folders
‚îÇ       ‚îú‚îÄ‚îÄ subject.txt              # Email subject (required)
‚îÇ       ‚îú‚îÄ‚îÄ body.html                # Email body HTML (required)  
‚îÇ       ‚îú‚îÄ‚îÄ from.txt                 # From address (required)
‚îÇ       ‚îú‚îÄ‚îÄ approver.txt             # Approver emails for dry-run (required)
‚îÇ       ‚îú‚îÄ‚îÄ to.txt                   # Direct recipient list (optional)
‚îÇ       ‚îú‚îÄ‚îÄ cc.txt                   # CC recipients (optional)
‚îÇ       ‚îú‚îÄ‚îÄ bcc.txt                  # BCC recipients (optional)
‚îÇ       ‚îú‚îÄ‚îÄ additional_to.txt        # Additional recipients (optional)
‚îÇ       ‚îú‚îÄ‚îÄ filter.txt               # CSV filter conditions (required for multi)
‚îÇ       ‚îú‚îÄ‚îÄ field.txt                # Fields for template substitution (optional)
‚îÇ       ‚îú‚îÄ‚îÄ table-columns.txt        # Columns for dynamic tables (optional, NEW)
‚îÇ       ‚îú‚îÄ‚îÄ mode.txt                 # Force mode: single|multi (optional)
‚îÇ       ‚îú‚îÄ‚îÄ field-inventory.csv      # Local field inventory (optional, NEW)
‚îÇ       ‚îú‚îÄ‚îÄ attachment/              # Email attachments folder (optional)
‚îÇ       ‚îú‚îÄ‚îÄ images/                  # Images for embedding (optional)
‚îÇ       ‚îî‚îÄ‚îÄ recipients/              # Generated recipient files (auto-created)
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îî‚îÄ‚îÄ inventory.csv                # Global CSV inventory (required for filters)
‚îú‚îÄ‚îÄ signature.html                   # Global email signature (optional)
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ notifybot.log                # Execution logs

ENHANCED FIELD VALIDATION SYSTEM
---------------------------------

Priority-Based Validation Rules:
1. filter.txt fields ‚Üí ALWAYS validated against /notifybot/inventory/inventory.csv (GLOBAL)
2. If local field-inventory.csv exists:
   - filter.txt fields ALSO validated against local field-inventory.csv 
   - field.txt fields validated against local field-inventory.csv (PRIORITY)
   - table-columns.txt fields validated against local field-inventory.csv (PRIORITY)
3. If no local field-inventory.csv:
   - field.txt fields validated against global inventory.csv (FALLBACK)
   - table-columns.txt fields validated against global inventory.csv (FALLBACK)

Dynamic Field Support:
- dynamic_table (legacy compatibility)
- table_rows (standard HTML table with styling)
- csv_table_rows (pipe-separated table rows)
- simple_table_rows (basic HTML table without styling)
- styled_table_rows (table with alternating row colors)
- table_headers (table headers based on CSV fields)

Dynamic fields require table-columns.txt file to define which CSV columns to include.

Field Name Validation:
- All field names stripped of whitespace for consistent matching
- Case-sensitive field name matching
- Comprehensive error reporting with available field suggestions
- Validation occurs before any email processing begins

OPERATING MODES
---------------

SINGLE MODE:
- Sends ONE email to multiple recipients
- Supports batching for large recipient lists
- Recipients from: to.txt, filters, additional_to.txt, cc.txt, bcc.txt
- Template substitution from first matching CSV row (if filters used)
- Requires at least one recipient source (enforced validation)

MULTI MODE:
- Sends MULTIPLE personalized emails based on filter conditions
- Each filter condition generates one unique email
- Each email can have different recipients and personalized content
- Template substitution from matching CSV rows per filter
- Requires filter.txt and global inventory.csv

FILTER SYNTAX (PromQL-style)
----------------------------
Enhanced filter syntax with comprehensive validation:

- Exact match: field="value"
- Not equal: field!="value"  
- Regex match: field=~"pattern"
- Regex not match: field!~"pattern"
- Wildcard: field=value* or field=*value* or field=val?e
- AND conditions: field1="value1",field2="value2"
- OR conditions: Put each condition on separate lines
- Comments: Lines starting with # are ignored

Examples:
  department="sales"                    # Exact match
  region!="europe"                      # Not equal
  name=~".*Manager.*"                   # Regex match  
  email!~".*(test|demo).*"              # Regex not match
  status=active*                        # Wildcard match
  department="sales",region="north"     # AND condition (same line)
  department="sales"                    # OR conditions
  department="marketing"                # (separate lines)
  # This is a comment                   # Ignored lines

Filter Validation Features:
- Syntax validation before processing
- Field name validation against inventory
- Regex pattern validation for =~ and !~ operators
- Detailed error reporting with line numbers
- Match statistics and performance reporting

TEMPLATE SUBSTITUTION
---------------------
Enhanced template substitution with table generation:

- Use {field_name} placeholders in subject.txt and body.html
- Values automatically extracted from matching CSV rows
- Comma-separated values are formatted nicely (smart formatting)
- Enhanced dynamic table generation:
  ‚Ä¢ {table_rows} - HTML table rows with styling
  ‚Ä¢ {simple_table_rows} - Basic HTML table rows  
  ‚Ä¢ {styled_table_rows} - Alternating row colors
  ‚Ä¢ {csv_table_rows} - Pipe-separated table data
  ‚Ä¢ {table_headers} - HTML table headers
  ‚Ä¢ {dynamic_table} - Complete styled table (legacy compatibility)

Table Generation Requirements:
- Requires table-columns.txt file listing desired CSV columns
- Each line in table-columns.txt specifies one column to include
- Columns must exist in the inventory CSV
- Supports all standard field validation rules

Template Processing Features:
- Smart comma-separated value formatting
- Empty field handling with placeholder preservation
- Multiple value aggregation (e.g., "value1, value2, and 3 more")
- HTML-safe content escaping for table generation

RECIPIENT MANAGEMENT
--------------------
Enhanced recipient processing with multiple sources:

Single Mode Recipients (requires at least ONE):
- to.txt: Direct recipient list
- filter.txt + inventory.csv: Filtered recipients
- additional_to.txt: Additional recipients (merged with main list)
- cc.txt: CC recipients (sent with every email)
- bcc.txt: BCC recipients (sent with every email)

Multi Mode Recipients:
- filter.txt: Required, each line creates separate email
- additional_to.txt: Added to ALL filter-generated emails
- cc.txt: Added to ALL generated emails
- bcc.txt: Added to ALL generated emails

Recipient Processing Features:
- Automatic deduplication (case-insensitive)
- Email format validation with sendmail compatibility
- Support for semicolon-separated lists in files
- Comprehensive logging of recipient sources and counts
- Merge conflict resolution (preserves order, removes duplicates)

ATTACHMENT MANAGEMENT
---------------------
Enhanced attachment handling with size validation:

Features:
- Automatic MIME type detection
- Base64 encoding for binary files
- Filename sanitization for compatibility
- Size limit validation (15MB default, configurable)
- Comprehensive attachment logging

Size Limit Validation:
- Validates total size of all files in attachment/ folder
- Prevents email server rejection due to oversized attachments
- Detailed size reporting per file and total
- Graceful error handling with clear error messages

Supported File Types:
- All file types supported via MIME type detection
- Binary files automatically base64 encoded
- Text files preserved with proper encoding
- Image files can be embedded in email body (separate from attachments)

IMAGE EMBEDDING
---------------
Advanced image embedding for HTML emails:

Features:
- Automatic conversion of local image references to CID
- Support for multiple image formats (JPEG, PNG, GIF, etc.)
- Proper MIME multipart/related message structure
- External URL preservation with warnings

Image Processing:
- Images from images/ folder automatically embedded
- Converts <img src="filename.jpg"> to <img src="cid:image_id">
- Maintains image quality and format
- Proper Content-ID and Content-Disposition headers

Supported Workflows:
- Place images in campaign-folder/images/
- Reference in HTML as src="filename.jpg"
- System automatically embeds and updates references
- External URLs preserved but may be blocked by email clients

SAFETY FEATURES
---------------
Enhanced safety with comprehensive validation:

‚Ä¢ Dry-run mode: Sends DRAFT emails to approvers only with original recipient counts
‚Ä¢ Email validation: Comprehensive syntax and deliverability checking with sendmail compatibility
‚Ä¢ Field validation: Priority-based validation ensures all template fields exist
‚Ä¢ Size limits: Attachment folder size validation with configurable limits
‚Ä¢ Deduplication: Automatic removal of duplicate email addresses (case-insensitive)
‚Ä¢ Error handling: Graceful failure handling with detailed logging and suggestions
‚Ä¢ Confirmation prompts: Interactive confirmation unless --force used
‚Ä¢ Pre-flight validation: All checks performed before any email sending begins

Dry-Run Mode Features:
- Sends to approvers only (from approver.txt)
- Adds DRAFT prefix to subject if not present
- Includes original recipient count information in email body
- Shows filter information for multi-mode campaigns
- Preserves original recipient lists for reference
- Comprehensive reporting of what would be sent in live mode

LOGGING & MONITORING
--------------------
Enhanced logging with CSV format and detailed tracking:

Log Format: timestamp_epoch,username,emoji_level_message
Log Location: /notifybot/logs/notifybot.log

Logging Features:
- Comprehensive audit trail for all operations
- Color-coded console output with emoji indicators
- Batch processing progress tracking
- Detailed error reporting and troubleshooting info
- Field validation results and statistics
- Recipient processing and deduplication logging
- Email delivery status tracking

Log Levels:
- info ‚ÑπÔ∏è: General information and progress updates
- success ‚úÖ: Successful operations and completions
- warning ‚ö†Ô∏è: Non-fatal issues and recommendations  
- error ‚ùå: Fatal errors and failures
- processing ‚è≥: Long-running operation progress
- confirmation ‚úã: User interaction and confirmations
- draft üìù: Dry-run mode specific information
- file üìÇ: File operations and data saving
- mode üîß: Mode detection and configuration
- signature ‚úçÔ∏è: Signature loading and processing

USAGE EXAMPLES
--------------
# Dry-run single mode campaign with field validation
python notifybot.py --base-folder my-campaign --dry-run

# Live multi-mode with custom batch settings and table generation
python notifybot.py --base-folder newsletter --mode multi --batch-size 200 --delay 10

# Force single mode without confirmation, custom attachment size limit
python notifybot.py --base-folder announcement --mode single --force

# Dry-run with local field inventory validation
python notifybot.py --base-folder survey --dry-run --batch-size 100

# Multi-mode with comprehensive logging and validation
python notifybot.py --base-folder personalized --mode multi --force --delay 5

COMMAND LINE OPTIONS
--------------------
Required:
  --base-folder BASE_FOLDER    Campaign folder name in /notifybot/basefolder/

Optional:
  --mode {single,multi}        Force mode (overrides mode.txt)
  --dry-run                    Send DRAFT emails to approvers only
  --force                      Skip confirmation prompt
  --batch-size INT             Emails per batch (default: 500)
  --delay FLOAT                Seconds between batches (default: 5.0)

ERROR HANDLING
--------------
Comprehensive error handling with detailed guidance:

Validation Errors:
- Missing required files with specific requirements per mode
- Invalid field names with available field suggestions
- Filter syntax errors with line numbers and examples
- Email format validation with specific issues identified
- Attachment size limit violations with size breakdowns

Runtime Errors:
- Sendmail delivery failures with specific error codes
- File access permissions and encoding issues
- Network timeouts and delivery delays
- CSV parsing errors with row and column identification

Recovery Features:
- Batch processing continues after individual batch failures
- Partial campaign completion tracking
- Detailed failure logging for troubleshooting
- Graceful degradation when optional features unavailable

PERFORMANCE OPTIMIZATION
-------------------------
Optimized for large-scale email campaigns:

Batch Processing:
- Configurable batch sizes for memory management
- Intelligent delay handling between batches
- Progress tracking and estimation
- Efficient recipient deduplication algorithms

Memory Management:
- Streaming CSV processing for large inventories
- Efficient template substitution caching
- Optimized attachment handling
- Memory-conscious image embedding

Network Efficiency:
- Sendmail integration for reliable delivery
- Configurable retry logic for failed batches
- Connection pooling and reuse
- Rate limiting compliance

COMPATIBILITY
-------------
System Requirements:
- Python 3.7+ (tested with 3.8, 3.9, 3.10, 3.11)
- Unix-like systems (Linux, macOS, WSL)
- Sendmail or compatible MTA installed
- Sufficient disk space for logs and temporary files

Dependencies:
- email_validator: Email format validation
- Standard library modules (csv, pathlib, subprocess, etc.)
- No additional external dependencies required

Email Client Compatibility:
- HTML email support (all major clients)
- Embedded image support (most modern clients)
- MIME multipart support (universal)
- Attachment support (universal)

TROUBLESHOOTING
---------------
Common Issues and Solutions:

1. "Field validation failed":
   - Check that field names in filter.txt/field.txt exist in inventory.csv
   - Verify CSV headers don't have extra spaces
   - Use --dry-run to see available fields in logs

2. "No recipients found":
   - Verify at least one recipient source exists (to.txt, filter.txt, cc.txt, etc.)
   - Check email format in recipient files
   - Review filter conditions for typos

3. "Sendmail not found":
   - Install sendmail: sudo apt-get install sendmail
   - Verify sendmail path in common locations
   - Check system mail configuration

4. "Attachment size limit exceeded":
   - Reduce attachment file sizes
   - Remove unnecessary files from attachment/ folder
   - Consider using file sharing links for large files

5. "Template substitution failed":
   - Verify field names match CSV headers exactly
   - Check for typos in placeholder names
   - Ensure CSV has data for filtered rows

AUTHOR & MAINTENANCE
--------------------
This enhanced system is designed for enterprise email campaign management with
emphasis on safety, auditability, operational reliability, and advanced CSV integration.

The priority-based validation system ensures data integrity while providing flexibility
for different organizational structures and workflows.

For support and documentation, see the built-in help:
python notifybot.py --help

Version: 4.0+ (Enhanced field validation with priority-based inventory system)
Compatible with: Python 3.7+
Dependencies: email_validator, standard library modules
License: Internal use - enterprise email automation system

CHANGELOG
---------
v4.0+ New Features:
- Priority-based field validation system
- Local field-inventory.csv support
- Enhanced table generation with table-columns.txt
- Improved attachment size validation
- Better error reporting and user guidance
- Enhanced recipient source validation
- Comprehensive whitespace handling in field names
- Dynamic field support with runtime table generation
- Backward compatibility with legacy dynamic_table field
- Improved logging with more detailed statistics
- Enhanced dry-run mode with better original recipient tracking
"""
import base64
import mimetypes
from email.mime.image import MIMEImage
from typing import List, Tuple, Dict, Set  
import re  
import argparse
import csv
import logging
import shutil
import sys
import time
import traceback
import os
import json
import fnmatch
import io
from datetime import datetime
from email.message import EmailMessage
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from pathlib import Path
import subprocess
from email_validator import validate_email, EmailNotValidError

# Path configurations
NOTIFYBOT_ROOT = Path("/notifybot")  # Root directory
BASEFOLDER_PATH = NOTIFYBOT_ROOT / "basefolder"  # Enforced base folder location
LOG_FILENAME = NOTIFYBOT_ROOT / "logs" / "notifybot.log"  # Log file location
INVENTORY_PATH = NOTIFYBOT_ROOT / "inventory" / "inventory.csv"  # New location of inventory.csv

def validate_fields_with_priority(base_folder: Path, mode: str = "single") -> Tuple[bool, List[str]]:
    """
    Enhanced validation with table-columns.txt support following the same priority-based validation system.
    
    Validation Rules:
    1. filter.txt fields are validated against global inventory (always required)
    2. If local field-inventory.csv exists, filter.txt fields are also validated against it
    3. field.txt fields are validated against local field-inventory.csv (if exists) OR global inventory (fallback)
    4. table-columns.txt fields follow same priority as field.txt (local -> global fallback)
    
    Args:
        base_folder (Path): Base folder containing configuration files
        mode (str): Operation mode - "single" or "multi"
    
    Returns:
        Tuple[bool, List[str]]: (is_valid, list_of_errors)
    """
    errors = []
    
    # Define dynamically generated fields that don't exist in CSV files
    DYNAMIC_FIELDS = {
        'dynamic_table',         # Original hardcoded microservice table (backward compatibility)
        'table_rows',           # Standard HTML table with styling
        'csv_table_rows',       # CSV-style table rows (pipe-separated)
        'simple_table_rows',    # Simple HTML table without styling
        'styled_table_rows',    # Table with alternating row colors
        'table_headers',        # Table headers based on CSV fields
    }
    
    # File paths
    table_columns_file = base_folder / "table-columns.txt"
    local_field_inventory_path = base_folder / "field-inventory.csv"
    filter_file = base_folder / "filter.txt"
    field_file = base_folder / "field.txt"
    
    # Check existence flags
    has_table_columns = table_columns_file.exists()
    has_local_field_inventory = local_field_inventory_path.exists()
    
    # Validate global inventory exists
    if not INVENTORY_PATH.exists():
        errors.append(f"Global inventory file not found: {INVENTORY_PATH}")
        return False, errors
    
    # Read and validate global inventory
    try:
        with open(INVENTORY_PATH, mode="r", newline="", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            if not reader.fieldnames:
                errors.append("Global inventory.csv has no headers")
                return False, errors
            
            # Strip whitespace from field names and remove empty fields
            global_available_fields = {field.strip() for field in reader.fieldnames if field and field.strip()}
            
        if not global_available_fields:
            errors.append("No valid headers found in global inventory.csv")
            return False, errors
            
        log_and_print("info", f"Global inventory loaded: {len(global_available_fields)} fields")
        
    except Exception as exc:
        errors.append(f"Error reading global inventory.csv: {exc}")
        return False, errors
    
    # Read and validate local field inventory if it exists
    local_available_fields = set()
    if has_local_field_inventory:
        try:
            with open(local_field_inventory_path, mode="r", newline="", encoding="utf-8") as file:
                reader = csv.DictReader(file)
                if not reader.fieldnames:
                    errors.append("Local field-inventory.csv has no headers")
                    return False, errors
                
                # Strip whitespace from field names and remove empty fields
                local_available_fields = {field.strip() for field in reader.fieldnames if field and field.strip()}
                
            if not local_available_fields:
                errors.append("No valid headers found in local field-inventory.csv")
                return False, errors
                
            log_and_print("info", f"Local field-inventory loaded: {len(local_available_fields)} fields")
            
        except Exception as exc:
            errors.append(f"Error reading local field-inventory.csv: {exc}")
            return False, errors
    
    # RULE 1: Validate filter.txt against both global and local inventories
    if filter_file.is_file():
        try:
            filter_content = read_file(filter_file)
            if not filter_content:
                log_and_print("warning", "filter.txt is empty")
            else:
                filter_lines = [line.strip() for line in filter_content.splitlines() 
                              if line.strip() and not line.strip().startswith('#')]
                
                if not filter_lines:
                    log_and_print("info", "filter.txt contains only comments or empty lines")
                else:
                    # Extract field names from filter conditions
                    filter_fields = set()
                    line_field_map = {}  # Track which line each field appears on
                    
                    for line_num, filter_line in enumerate(filter_lines, 1):
                        # Split by commas for AND conditions
                        conditions = [condition.strip() for condition in filter_line.split(',')]
                        
                        for condition in conditions:
                            if not condition:
                                continue
                            
                            # Extract field name from condition (before operator)
                            field_name = None
                            for op in ['=~', '!~', '!=', '=']:
                                if op in condition:
                                    parts = condition.split(op, 1)
                                    if len(parts) >= 2:
                                        field_name = parts[0].strip()
                                        break
                            
                            if field_name:
                                filter_fields.add(field_name)
                                if field_name not in line_field_map:
                                    line_field_map[field_name] = []
                                line_field_map[field_name].append(line_num)
                    
                    if filter_fields:
                        # Validate against global inventory (always required)
                        invalid_global = filter_fields - global_available_fields
                        for field_name in invalid_global:
                            line_nums = line_field_map[field_name]
                            lines_str = ', '.join(map(str, line_nums))
                            errors.append(f"filter.txt line(s) {lines_str}: Field '{field_name}' not found in global inventory.csv")
                        
                        # Validate against local inventory if it exists
                        if has_local_field_inventory:
                            invalid_local = filter_fields - local_available_fields
                            for field_name in invalid_local:
                                line_nums = line_field_map[field_name]
                                lines_str = ', '.join(map(str, line_nums))
                                errors.append(f"filter.txt line(s) {lines_str}: Field '{field_name}' not found in local field-inventory.csv")
                        
                        # Success logging
                        if not invalid_global:
                            log_and_print("info", f"filter.txt: All {len(filter_fields)} field(s) validated against global inventory")
                        if has_local_field_inventory and not invalid_local:
                            log_and_print("info", f"filter.txt: All {len(filter_fields)} field(s) validated against local field-inventory")
                        
        except Exception as exc:
            errors.append(f"Error validating filter.txt: {exc}")
    
    # RULE 2 & 3: Validate field.txt - ONLY in multi mode
    if mode == "multi" and field_file.is_file():
        try:
            field_content = read_file(field_file)
            if not field_content:
                log_and_print("info", "field.txt is empty - no fields to validate")
            else:
                field_names = [line.strip() for line in field_content.splitlines() if line.strip()]
                
                if field_names:
                    # Determine which inventory to validate against (priority: local -> global)
                    if has_local_field_inventory:
                        inventory_to_use = local_available_fields
                        inventory_name = "local field-inventory.csv"
                        log_and_print("info", f"field.txt: Using local field-inventory.csv (priority)")
                    else:
                        inventory_to_use = global_available_fields
                        inventory_name = "global inventory.csv"
                        log_and_print("info", f"field.txt: Using global inventory.csv (fallback)")
                    
                    invalid_fields = []
                    dynamic_fields_found = []
                    valid_csv_fields = []
                    
                    for line_num, field_name in enumerate(field_names, 1):
                        field_name = field_name.strip()
                        
                        if not field_name:  # Skip empty field names
                            continue
                        
                        # Check if it's a dynamic field that requires table-columns.txt
                        if field_name in DYNAMIC_FIELDS:
                            if not has_table_columns:
                                errors.append(f"field.txt line {line_num}: Dynamic field '{field_name}' requires table-columns.txt file")
                            else:
                                dynamic_fields_found.append(field_name)
                                log_and_print("info", f"field.txt line {line_num}: '{field_name}' is a valid dynamic field")
                        # Check if field exists in chosen inventory
                        elif field_name in inventory_to_use:
                            valid_csv_fields.append(field_name)
                        else:
                            invalid_fields.append((field_name, line_num))
                            errors.append(f"field.txt line {line_num}: Field '{field_name}' not found in {inventory_name}")
                    
                    # Success logging
                    if valid_csv_fields:
                        log_and_print("info", f"field.txt: {len(valid_csv_fields)} CSV field(s) validated against {inventory_name}")
                    if dynamic_fields_found:
                        log_and_print("info", f"field.txt: {len(dynamic_fields_found)} dynamic field(s) validated")
                    
                    # Error summary
                    if invalid_fields:
                        field_names_only = [field for field, _ in invalid_fields]
                        log_and_print("error", f"field.txt: Invalid fields in {inventory_name}: {', '.join(field_names_only)}")
                        
        except Exception as exc:
            errors.append(f"Error validating field.txt: {exc}")
    elif mode == "multi":
        log_and_print("info", "field.txt not found (optional for multi mode)")
    
    # RULE 4: Validate table-columns.txt - ONLY when it exists
    if has_table_columns:
        try:
            table_columns_content = read_file(table_columns_file)
            if not table_columns_content:
                log_and_print("info", "table-columns.txt is empty - no table columns to validate")
            else:
                table_column_names = [line.strip() for line in table_columns_content.splitlines() if line.strip()]
                
                if table_column_names:
                    # Determine which inventory to validate against (same logic as field.txt)
                    if has_local_field_inventory:
                        inventory_to_use = local_available_fields
                        inventory_name = "local field-inventory.csv"
                        log_and_print("info", f"table-columns.txt: Using local field-inventory.csv (priority)")
                    else:
                        inventory_to_use = global_available_fields
                        inventory_name = "global inventory.csv"
                        log_and_print("info", f"table-columns.txt: Using global inventory.csv (fallback)")
                    
                    invalid_table_fields = []
                    valid_table_fields = []
                    
                    for line_num, field_name in enumerate(table_column_names, 1):
                        field_name = field_name.strip()
                        
                        if not field_name:  # Skip empty field names
                            continue
                        
                        if field_name in inventory_to_use:
                            valid_table_fields.append(field_name)
                        else:
                            invalid_table_fields.append((field_name, line_num))
                            errors.append(f"table-columns.txt line {line_num}: Field '{field_name}' not found in {inventory_name}")
                    
                    # Success logging
                    if valid_table_fields:
                        log_and_print("info", f"table-columns.txt: {len(valid_table_fields)} field(s) validated against {inventory_name}")
                    
                    # Error summary
                    if invalid_table_fields:
                        field_names_only = [field for field, _ in invalid_table_fields]
                        log_and_print("error", f"table-columns.txt: Invalid fields in {inventory_name}: {', '.join(field_names_only)}")
                        
        except Exception as exc:
            errors.append(f"Error validating table-columns.txt: {exc}")
    
    # Provide helpful suggestions if there are errors
    if errors:
        log_and_print("info", "Field validation failed. Available fields:")
        
        # Show global fields
        sorted_global = sorted(global_available_fields)
        if len(sorted_global) <= 10:
            log_and_print("info", f"Global inventory.csv: {', '.join(sorted_global)}")
        else:
            log_and_print("info", f"Global inventory.csv: {', '.join(sorted_global[:10])}... and {len(sorted_global)-10} more")
        
        # Show local fields if available
        if has_local_field_inventory:
            sorted_local = sorted(local_available_fields)
            if len(sorted_local) <= 10:
                log_and_print("info", f"Local field-inventory.csv: {', '.join(sorted_local)}")
            else:
                log_and_print("info", f"Local field-inventory.csv: {', '.join(sorted_local[:10])}... and {len(sorted_local)-10} more")
        
        # Show dynamic fields
        if DYNAMIC_FIELDS:
            sorted_dynamic = sorted(DYNAMIC_FIELDS)
            if has_table_columns:
                log_and_print("info", f"Dynamic fields (table-columns.txt found): {', '.join(sorted_dynamic)}")
            else:
                log_and_print("info", f"Dynamic fields (require table-columns.txt): {', '.join(sorted_dynamic)}")
    else:
        log_and_print("success", "All field validations passed successfully")
    
    return len(errors) == 0, errors


def check_attachment_size_limit(base_folder: Path, max_size_mb: int = 15) -> None:
    """
    Check attachment size limit with enhanced validation, detailed reporting, and better error handling.
    
    Args:
        base_folder: Base folder path containing potential attachment subfolder
        max_size_mb: Maximum total attachment size in MB (default: 15)
    
    Raises:
        MissingRequiredFilesError: If attachment size exceeds limit or validation fails
    """
    attachment_folder = base_folder / "attachment"
    
    # Early return if no attachment folder exists
    if not attachment_folder.exists():
        log_and_print("info", "No attachment folder found - skipping attachment validation")
        return
    
    if not attachment_folder.is_dir():
        log_and_print("warning", "attachment path exists but is not a directory - skipping")
        return
    
    # Initialize tracking variables
    total_size_bytes = 0
    file_count = 0
    processed_files = []
    error_files = []
    large_files = []
    empty_files = []
    
    # Define size thresholds for warnings
    LARGE_FILE_THRESHOLD_MB = 5.0  # Warn for individual files > 5MB
    max_size_bytes = max_size_mb * 1024 * 1024
    
    try:
        # Get all files in attachment folder
        all_items = list(attachment_folder.iterdir())
        
        if not all_items:
            log_and_print("info", "Attachment folder exists but is empty")
            return
        
        # Process each item in the attachment folder
        for item_path in all_items:
            try:
                if item_path.is_file():
                    file_size = item_path.stat().st_size
                    file_size_mb = file_size / (1024 * 1024)
                    
                    # Track file info
                    file_info = {
                        'name': item_path.name,
                        'size_bytes': file_size,
                        'size_mb': file_size_mb
                    }
                    processed_files.append(file_info)
                    
                    # Add to totals
                    total_size_bytes += file_size
                    file_count += 1
                    
                    # Check for large individual files
                    if file_size_mb > LARGE_FILE_THRESHOLD_MB:
                        large_files.append(file_info)
                    
                    # Check for empty files
                    if file_size == 0:
                        empty_files.append(file_info)
                    
                    # Log individual file (with appropriate level)
                    if file_size_mb > LARGE_FILE_THRESHOLD_MB:
                        log_and_print("warning", f"Large attachment: {item_path.name} ({file_size_mb:.2f} MB)")
                    else:
                        log_and_print("info", f"Attachment: {item_path.name} ({file_size_mb:.2f} MB)")
                        
                elif item_path.is_dir():
                    log_and_print("warning", f"Subdirectory found in attachments (will be ignored): {item_path.name}")
                else:
                    log_and_print("warning", f"Non-file item found in attachments (will be ignored): {item_path.name}")
                    
            except (OSError, PermissionError) as file_exc:
                error_files.append({'name': item_path.name, 'error': str(file_exc)})
                log_and_print("error", f"Cannot access attachment file {item_path.name}: {file_exc}")
                
        # Handle case where no valid files were found
        if file_count == 0:
            if error_files:
                log_and_print("error", f"No accessible attachment files found ({len(error_files)} files had errors)")
                raise MissingRequiredFilesError(
                    f"Cannot validate attachments: {len(error_files)} files are inaccessible"
                )
            else:
                log_and_print("info", "Attachment folder contains no files")
                return
        
        # Calculate total size
        total_size_mb = total_size_bytes / (1024 * 1024)
        
        # Detailed reporting
        log_and_print("info", f"Attachment summary: {file_count} file(s), {total_size_mb:.2f} MB total")
        
        # Report warnings for large files
        if large_files:
            log_and_print("warning", f"Found {len(large_files)} large file(s) (>{LARGE_FILE_THRESHOLD_MB}MB each):")
            for file_info in large_files:
                log_and_print("warning", f"  - {file_info['name']}: {file_info['size_mb']:.2f} MB")
        
        # Report empty files
        if empty_files:
            log_and_print("warning", f"Found {len(empty_files)} empty file(s):")
            for file_info in empty_files:
                log_and_print("warning", f"  - {file_info['name']}: 0 bytes")
        
        # Report file access errors
        if error_files:
            log_and_print("warning", f"Could not access {len(error_files)} file(s):")
            for error_info in error_files:
                log_and_print("warning", f"  - {error_info['name']}: {error_info['error']}")
        
        # Size limit validation
        if total_size_mb > max_size_mb:
            # Calculate how much over the limit
            excess_mb = total_size_mb - max_size_mb
            percentage_over = (excess_mb / max_size_mb) * 100
            
            # Provide helpful suggestions
            suggestions = []
            
            if large_files:
                largest_file = max(large_files, key=lambda x: x['size_mb'])
                suggestions.append(f"Consider removing or compressing large files (largest: {largest_file['name']} at {largest_file['size_mb']:.2f} MB)")
            
            if empty_files:
                suggestions.append(f"Remove {len(empty_files)} empty file(s)")
            
            if len(processed_files) > 10:
                suggestions.append("Consider splitting attachments across multiple emails")
            
            # Create detailed error message
            error_msg = (
                f"Attachment size limit exceeded: {total_size_mb:.2f} MB > {max_size_mb} MB limit "
                f"({excess_mb:.2f} MB over, {percentage_over:.1f}% excess). "
            )
            
            if suggestions:
                error_msg += f"Suggestions: {'; '.join(suggestions)}."
            else:
                error_msg += "Please reduce the total size of files in the attachment folder."
            
            log_and_print("error", error_msg)
            raise MissingRequiredFilesError(error_msg)
        
        # Success message with utilization info
        utilization_percentage = (total_size_mb / max_size_mb) * 100
        remaining_mb = max_size_mb - total_size_mb
        
        if utilization_percentage > 80:  # Warn if >80% utilized
            log_and_print("warning", f"Attachment size check passed but high utilization: {total_size_mb:.2f} MB / {max_size_mb} MB ({utilization_percentage:.1f}%, {remaining_mb:.2f} MB remaining)")
        else:
            log_and_print("success", f"Attachment size check passed: {total_size_mb:.2f} MB / {max_size_mb} MB ({utilization_percentage:.1f}% utilized)")
            
        # Additional validation suggestions
        if file_count > 20:
            log_and_print("info", f"Large number of attachments ({file_count} files) - consider consolidating")
            
        if any(file_info['size_mb'] > max_size_mb * 0.8 for file_info in processed_files):
            log_and_print("info", "Some individual files are close to the total limit - monitor for multi-recipient compatibility")
            
    except MissingRequiredFilesError:
        # Re-raise our custom exception without modification
        raise
    except (OSError, PermissionError) as exc:
        error_msg = f"Cannot access attachment folder: {exc}"
        log_and_print("error", error_msg)
        raise MissingRequiredFilesError(error_msg)
    except Exception as exc:
        error_msg = f"Unexpected error during attachment validation: {exc}"
        log_and_print("error", error_msg)
        log_and_print("error", f"Attachment validation traceback: {traceback.format_exc()}")
        raise MissingRequiredFilesError(error_msg)



def check_required_files(base: Path, required: List[str], dry_run: bool = True, mode: str = "single") -> None:
    """
    Enhanced required files validation with comprehensive recipient source checking,
    detailed error reporting, and improved field validation.
    
    Args:
        base: Base folder path containing input files
        required: List of required file names
        dry_run: Whether running in dry-run mode
        mode: Operating mode ('single' or 'multi')
    
    Raises:
        MissingRequiredFilesError: If validation fails
    """
    validation_errors = []
    warnings = []
    
    # Phase 1: Basic required files validation
    log_and_print("info", f"Phase 1: Checking {len(required)} required files...")
    missing_required = []
    found_required = []
    
    for filename in required:
        file_path = base / filename
        if file_path.is_file():
            # Additional validation for non-empty files
            try:
                content = file_path.read_text(encoding="utf-8").strip()
                if not content:
                    warnings.append(f"Required file '{filename}' exists but is empty")
                    log_and_print("warning", f"Required file '{filename}' is empty")
                else:
                    found_required.append(filename)
                    log_and_print("info", f"‚úì Required file: {filename} ({len(content)} chars)")
            except Exception as exc:
                validation_errors.append(f"Cannot read required file '{filename}': {exc}")
                log_and_print("error", f"Cannot read required file '{filename}': {exc}")
        else:
            missing_required.append(filename)
            log_and_print("error", f"‚úó Missing required file: {filename}")
    
    if missing_required:
        validation_errors.append(f"Missing required files: {', '.join(missing_required)}")
    
    if found_required:
        log_and_print("success", f"Found {len(found_required)} required files")
    
    # Phase 2: Mode-specific validation
    log_and_print("info", f"Phase 2: Mode-specific validation for '{mode}' mode...")
    
    if mode == "multi":
        # Multi mode requires filter.txt and inventory
        multi_errors = validate_multi_mode_requirements(base)
        validation_errors.extend(multi_errors)
        
    elif mode == "single":
        # Single mode requires at least one recipient source
        single_errors, single_warnings = validate_single_mode_requirements(base, dry_run)
        validation_errors.extend(single_errors)
        warnings.extend(single_warnings)
    
    # Phase 3: Field validation (if applicable)
    needs_field_validation = (
        mode == "multi" or 
        (mode == "single" and (base / "filter.txt").is_file())
    )
    
    if needs_field_validation:
        log_and_print("info", "Phase 3: Field validation with priority-based inventory checking...")
        field_validation_errors = perform_field_validation(base, mode)
        validation_errors.extend(field_validation_errors)
    else:
        log_and_print("info", "Phase 3: Skipping field validation (not required for this configuration)")
    
    # Phase 4: Optional files and advanced validation
    log_and_print("info", "Phase 4: Optional files and advanced validation...")
    optional_warnings = validate_optional_files(base, mode)
    warnings.extend(optional_warnings)
    
    # Phase 5: Attachment validation
    log_and_print("info", "Phase 5: Attachment validation...")
    try:
        check_attachment_size_limit(base)
    except MissingRequiredFilesError as exc:
        validation_errors.append(str(exc))
    
    # Phase 6: Summary and error handling
    log_and_print("info", "Phase 6: Validation summary...")
    
    # Report warnings (non-fatal)
    if warnings:
        log_and_print("warning", f"Found {len(warnings)} warnings:")
        for warning in warnings:
            log_and_print("warning", f"  - {warning}")
    
    # Handle fatal errors
    if validation_errors:
        log_and_print("error", f"Validation failed with {len(validation_errors)} error(s):")
        for error in validation_errors:
            log_and_print("error", f"  - {error}")
        
        # Provide helpful suggestions
        provide_validation_suggestions(base, mode, validation_errors)
        
        # Create comprehensive error message
        error_summary = f"File validation failed. {len(validation_errors)} error(s) found."
        if warnings:
            error_summary += f" Also found {len(warnings)} warning(s)."
        
        raise MissingRequiredFilesError(error_summary)
    
    # Success message
    total_checks = len(required) + (1 if needs_field_validation else 0) + 1  # +1 for attachments
    success_msg = f"All validation checks passed ({total_checks} phases completed)"
    if warnings:
        success_msg += f" with {len(warnings)} warning(s)"
    
    log_and_print("success", success_msg)


def validate_multi_mode_requirements(base_folder: Path, dry_run: bool = True) -> None:
    """
    Comprehensive validation for multi-mode requirements with enhanced error reporting.
    
    Multi-mode requires:
    1. filter.txt (mandatory) - defines recipient filtering conditions
    2. Global inventory.csv at /notifybot/inventory/inventory.csv (mandatory)
    3. field.txt (optional) - for template substitution
    4. table-columns.txt (optional) - for dynamic table generation
    5. local field-inventory.csv (optional) - overrides global inventory for field validation
    6. Valid field names in filter.txt and field.txt must exist in appropriate inventory
    7. Dynamic table fields require table-columns.txt
    8. At least one valid filter condition that matches recipients
    9. Standard email files (subject.txt, body.html, from.txt, approver.txt)
    
    Args:
        base_folder: Path to the base folder containing configuration files
        dry_run: Whether this is a dry-run validation (affects some checks)
        
    Raises:
        MissingRequiredFilesError: If critical requirements are not met
    """
    errors = []
    warnings = []
    
    # === 1. MANDATORY FILES CHECK ===
    log_and_print("info", "üîç Multi-mode validation: Checking mandatory files...")
    
    # Core multi-mode files
    filter_file = base_folder / "filter.txt"
    if not filter_file.is_file():
        errors.append("filter.txt is required for multi-mode operation")
    
    if not INVENTORY_PATH.is_file():
        errors.append(f"Global inventory.csv is required at {INVENTORY_PATH}")
    
    # Standard email files
    required_email_files = ["subject.txt", "body.html", "from.txt", "approver.txt"]
    missing_email_files = [f for f in required_email_files if not (base_folder / f).is_file()]
    if missing_email_files:
        errors.append(f"Missing required email files: {', '.join(missing_email_files)}")
    
    # === 2. OPTIONAL FILES DETECTION ===
    field_file = base_folder / "field.txt"
    table_columns_file = base_folder / "table-columns.txt"
    local_field_inventory = base_folder / "field-inventory.csv"
    
    has_field_txt = field_file.is_file()
    has_table_columns = table_columns_file.is_file()
    has_local_inventory = local_field_inventory.is_file()
    
    log_and_print("info", f"Optional files detected:")
    log_and_print("info", f"  - field.txt: {'‚úì' if has_field_txt else '‚úó'} (template substitution)")
    log_and_print("info", f"  - table-columns.txt: {'‚úì' if has_table_columns else '‚úó'} (dynamic tables)")
    log_and_print("info", f"  - local field-inventory.csv: {'‚úì' if has_local_inventory else '‚úó'} (custom field validation)")
    
    # Early return if critical files are missing
    if errors:
        for error in errors:
            log_and_print("error", f"‚ùå {error}")
        raise MissingRequiredFilesError(f"Multi-mode validation failed: {len(errors)} critical error(s)")
    
    # === 3. INVENTORY VALIDATION & FIELD LOADING ===
    log_and_print("info", "üìä Loading and validating inventory files...")
    
    # Load global inventory fields
    try:
        with open(INVENTORY_PATH, mode="r", newline="", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            global_fields = set(field.strip() for field in (reader.fieldnames or []))
            
        if not global_fields:
            errors.append("Global inventory.csv contains no headers")
        else:
            log_and_print("info", f"Global inventory: {len(global_fields)} fields available")
            
    except Exception as exc:
        errors.append(f"Error reading global inventory.csv: {exc}")
        global_fields = set()
    
    # Load local inventory fields if present
    local_fields = set()
    if has_local_inventory:
        try:
            with open(local_field_inventory, mode="r", newline="", encoding="utf-8") as file:
                reader = csv.DictReader(file)
                local_fields = set(field.strip() for field in (reader.fieldnames or []))
                
            if not local_fields:
                warnings.append("Local field-inventory.csv exists but contains no headers")
            else:
                log_and_print("info", f"Local field-inventory: {len(local_fields)} fields available (overrides global for field validation)")
                
        except Exception as exc:
            warnings.append(f"Error reading local field-inventory.csv: {exc}")
    
    # Determine which inventory to use for field validation
    validation_fields = local_fields if has_local_inventory and local_fields else global_fields
    validation_source = "local field-inventory.csv" if has_local_inventory and local_fields else "global inventory.csv"
    
    # === 4. FILTER.TXT VALIDATION ===
    log_and_print("info", "üîç Validating filter.txt conditions...")
    
    try:
        filter_content = read_file(filter_file)
        filter_lines = [line.strip() for line in filter_content.splitlines() 
                       if line.strip() and not line.strip().startswith('#')]
        
        if not filter_lines:
            errors.append("filter.txt contains no active filter conditions (only comments/empty lines)")
        else:
            log_and_print("info", f"Found {len(filter_lines)} active filter condition(s)")
            
            # Validate filter syntax and field names
            filter_errors = []
            filter_fields = set()
            
            for line_num, filter_line in enumerate(filter_lines, 1):
                # Extract field names from filter conditions
                conditions = [condition.strip() for condition in filter_line.split(',')]
                
                for condition in conditions:
                    if not condition:
                        continue
                    
                    # Extract field name from condition
                    field_name = None
                    for op in ['=~', '!~', '!=', '=']:
                        if op in condition:
                            field_name = condition.split(op)[0].strip()
                            break
                    
                    if field_name:
                        filter_fields.add(field_name)
                        
                        # Validate against global inventory (always required)
                        if field_name not in global_fields:
                            filter_errors.append(f"Line {line_num}: Field '{field_name}' not found in global inventory.csv")
                        
                        # Validate against local inventory if it exists
                        if has_local_inventory and local_fields and field_name not in local_fields:
                            filter_errors.append(f"Line {line_num}: Field '{field_name}' not found in local field-inventory.csv")
            
            if filter_errors:
                errors.extend(filter_errors)
                log_and_print("error", f"Filter validation failed: {len(filter_errors)} field error(s)")
            else:
                log_and_print("success", f"Filter validation passed: {len(filter_fields)} unique field(s) validated")
                
    except Exception as exc:
        errors.append(f"Error validating filter.txt: {exc}")
    
    # === 5. FIELD.TXT VALIDATION (if present) ===
    if has_field_txt:
        log_and_print("info", "üîç Validating field.txt for template substitution...")
        
        try:
            field_content = read_file(field_file)
            field_names = [line.strip() for line in field_content.splitlines() if line.strip()]
            
            if not field_names:
                warnings.append("field.txt exists but contains no field names")
            else:
                log_and_print("info", f"Found {len(field_names)} field(s) for template substitution")
                
                # Define dynamic fields that require table-columns.txt
                DYNAMIC_FIELDS = {
                    'dynamic_table', 'table_rows', 'csv_table_rows', 'simple_table_rows',
                    'styled_table_rows', 'table_headers'
                }
                
                field_errors = []
                dynamic_fields_found = []
                csv_fields_found = []
                
                for line_num, field_name in enumerate(field_names, 1):
                    field_name = field_name.strip()
                    
                    # Check for dynamic fields
                    if field_name in DYNAMIC_FIELDS:
                        if not has_table_columns:
                            field_errors.append(f"Line {line_num}: Dynamic field '{field_name}' requires table-columns.txt which is missing")
                        else:
                            dynamic_fields_found.append(field_name)
                    else:
                        # Regular CSV field - validate against appropriate inventory
                        csv_fields_found.append(field_name)
                        if field_name not in validation_fields:
                            field_errors.append(f"Line {line_num}: Field '{field_name}' not found in {validation_source}")
                
                if field_errors:
                    errors.extend(field_errors)
                    log_and_print("error", f"Field.txt validation failed: {len(field_errors)} error(s)")
                else:
                    log_and_print("success", f"Field.txt validation passed:")
                    if csv_fields_found:
                        log_and_print("success", f"  - {len(csv_fields_found)} CSV field(s) validated against {validation_source}")
                    if dynamic_fields_found:
                        log_and_print("success", f"  - {len(dynamic_fields_found)} dynamic field(s) validated")
                
        except Exception as exc:
            errors.append(f"Error validating field.txt: {exc}")
    else:
        log_and_print("info", "No field.txt found - template substitution will not be performed")
    
    # === 6. TABLE-COLUMNS.TXT VALIDATION (if present) ===
    if has_table_columns:
        log_and_print("info", "üîç Validating table-columns.txt for dynamic tables...")
        
        try:
            table_content = read_file(table_columns_file)
            table_fields = [line.strip() for line in table_content.splitlines() if line.strip()]
            
            if not table_fields:
                warnings.append("table-columns.txt exists but contains no field names")
            else:
                log_and_print("info", f"Found {len(table_fields)} table column(s)")
                
                table_errors = []
                for line_num, field_name in enumerate(table_fields, 1):
                    field_name = field_name.strip()
                    if field_name not in validation_fields:
                        table_errors.append(f"Line {line_num}: Table column '{field_name}' not found in {validation_source}")
                
                if table_errors:
                    errors.extend(table_errors)
                    log_and_print("error", f"Table-columns.txt validation failed: {len(table_errors)} error(s)")
                else:
                    log_and_print("success", f"Table-columns.txt validation passed: {len(table_fields)} column(s) validated")
                
        except Exception as exc:
            errors.append(f"Error validating table-columns.txt: {exc}")
    
    # === 7. RECIPIENT COUNT VALIDATION ===
    log_and_print("info", "üë• Validating recipient availability...")
    
    # Test filter conditions to ensure they will generate recipients
    if not errors:  # Only if no previous errors
        try:
            total_potential_recipients = 0
            working_filters = 0
            
            for i, filter_line in enumerate(filter_lines, 1):
                test_recipients = apply_filter_logic([filter_line], INVENTORY_PATH)
                recipient_count = len(deduplicate_emails(test_recipients))
                
                if recipient_count > 0:
                    working_filters += 1
                    total_potential_recipients += recipient_count
                    log_and_print("info", f"Filter {i}: {recipient_count} potential recipient(s)")
                else:
                    warnings.append(f"Filter {i} matches no recipients: {filter_line}")
            
            if working_filters == 0:
                errors.append("No filter conditions match any recipients in inventory.csv")
            else:
                log_and_print("success", f"Recipient validation: {working_filters}/{len(filter_lines)} filters will generate emails")
                log_and_print("success", f"Total potential recipients: {total_potential_recipients}")
                
                if working_filters < len(filter_lines):
                    warnings.append(f"{len(filter_lines) - working_filters} filter(s) will generate no emails")
                
        except Exception as exc:
            warnings.append(f"Could not validate recipient counts: {exc}")
    
    # === 8. ATTACHMENT SIZE VALIDATION ===
    try:
        check_attachment_size_limit(base_folder)
    except MissingRequiredFilesError as e:
        errors.append(str(e))
    except Exception as e:
        warnings.append(f"Attachment validation warning: {e}")
    
    # === 9. ADDITIONAL RECIPIENTS VALIDATION ===
    additional_files = ["additional_to.txt", "cc.txt", "bcc.txt"]
    for filename in additional_files:
        file_path = base_folder / filename
        if file_path.is_file():
            try:
                recipients = read_recipients(file_path)
                if recipients:
                    log_and_print("info", f"Found {len(recipients)} valid recipient(s) in {filename}")
                else:
                    warnings.append(f"{filename} exists but contains no valid email addresses")
            except Exception as exc:
                warnings.append(f"Error reading {filename}: {exc}")
    
    # === 10. SUMMARY AND ERROR REPORTING ===
    log_and_print("info", "üìã Multi-mode validation summary:")
    
    if warnings:
        log_and_print("warning", f"Found {len(warnings)} warning(s):")
        for warning in warnings:
            log_and_print("warning", f"  ‚ö†Ô∏è  {warning}")
    
    if errors:
        log_and_print("error", f"Multi-mode validation FAILED with {len(errors)} error(s):")
        for error in errors:
            log_and_print("error", f"  ‚ùå {error}")
        
        # Provide helpful suggestions
        log_and_print("info", "üí° Available resources:")
        if global_fields:
            log_and_print("info", f"Global inventory fields: {', '.join(sorted(global_fields))}")
        if local_fields:
            log_and_print("info", f"Local inventory fields: {', '.join(sorted(local_fields))}")
        
        raise MissingRequiredFilesError(
            f"Multi-mode validation failed with {len(errors)} error(s). "
            "Please fix the issues above before proceeding."
        )
    else:
        log_and_print("success", "‚úÖ Multi-mode validation completed successfully!")
        
        # Show configuration summary
        log_and_print("info", "üéØ Multi-mode configuration:")
        log_and_print("info", f"  - Active filters: {len(filter_lines) if 'filter_lines' in locals() else 'N/A'}")
        log_and_print("info", f"  - Template substitution: {'Enabled' if has_field_txt else 'Disabled'}")
        log_and_print("info", f"  - Dynamic tables: {'Enabled' if has_table_columns else 'Disabled'}")
        log_and_print("info", f"  - Field validation source: {validation_source}")
        if warnings:
            log_and_print("info", f"  - Warnings: {len(warnings)} (see above)")


def print_filter_syntax_help() -> None:
    """Print comprehensive help for filter.txt syntax."""
    help_text = """
FILTER.TXT SYNTAX HELP:
======================

Multi-mode uses filter.txt to define recipient selection criteria.
Each line represents an OR condition, and commas within a line create AND conditions.

SUPPORTED OPERATORS:
  =     Exact match (case-insensitive)
  !=    Not equal (case-insensitive) 
  =~    Regex match (case-insensitive)
  !~    Regex not match (case-insensitive)
  *     Wildcard patterns (*, ?, [])

SYNTAX EXAMPLES:
  department=Engineering                    # Exact match
  status!=inactive                          # Not equal
  email=~.*@company\\.com$                 # Regex match
  location!~^(Remote|WFH)                  # Regex not match
  name=John*                               # Wildcard match
  
MULTI-CONDITION EXAMPLES (AND logic within line):
  department=Engineering,status=active     # Engineering AND active
  location=NYC,role=~.*manager.*          # NYC AND role contains "manager"
  
MULTI-LINE EXAMPLES (OR logic between lines):
  department=Engineering
  department=Marketing
  # Results: All Engineering OR Marketing employees

ADVANCED COMBINATIONS:
  department=Engineering,status=active
  department=Marketing,role=Manager
  # Results: (Engineering AND active) OR (Marketing AND Manager)

COMMENTS AND FORMATTING:
  # Lines starting with # are comments
  department=Engineering    # End-of-line comments work too
                           # Empty lines are ignored

FIELD VALIDATION:
  - All field names must exist in inventory.csv
  - Use --help to see available fields
  - Field names are case-sensitive
  - Values are case-insensitive for most operators

REGEX TIPS:
  - Use =~ for "contains": name=~smith
  - Use ^ for "starts with": email=~^admin
  - Use $ for "ends with": email=~@company\\.com$  
  - Escape dots: domain=~\\.edu$
  - Use .* for "contains anywhere": role=~.*manager.*
"""
    print(help_text)


def validate_single_mode_requirements(base_folder: Path, dry_run: bool = True) -> None:
    """
    Fine-tuned validation function specifically for single mode operations.
    Provides detailed validation with clear error messages and helpful suggestions.
    
    Args:
        base_folder: Path to the base folder containing email configuration files
        dry_run: Whether this is a dry-run operation (affects some validation rules)
        
    Raises:
        MissingRequiredFilesError: If validation fails
    """
    errors = []
    warnings = []
    
    # 1. CORE REQUIRED FILES - Always needed for single mode
    core_files = {
        "subject.txt": "Email subject line",
        "body.html": "Email body content (HTML format)",
        "from.txt": "Sender email address",
        "approver.txt": "Approver email addresses (required for dry-run mode)"
    }
    
    log_and_print("info", "Validating single mode requirements...")
    
    # Check core files
    for filename, description in core_files.items():
        file_path = base_folder / filename
        if not file_path.is_file():
            errors.append(f"Missing {filename} - {description}")
        else:
            # Validate content is not empty
            try:
                content = file_path.read_text(encoding="utf-8").strip()
                if not content:
                    errors.append(f"{filename} exists but is empty - {description}")
                else:
                    log_and_print("info", f"‚úì {filename} found and has content")
            except Exception as exc:
                errors.append(f"Cannot read {filename}: {exc}")
    
    # 2. RECIPIENT SOURCE VALIDATION - At least one must exist
    recipient_sources = {}
    
    # Check to.txt
    to_file = base_folder / "to.txt"
    if to_file.is_file():
        try:
            to_emails = read_recipients(to_file)
            if to_emails:
                recipient_sources["to.txt"] = len(to_emails)
                log_and_print("info", f"‚úì to.txt found with {len(to_emails)} recipient(s)")
            else:
                warnings.append("to.txt exists but contains no valid email addresses")
        except Exception as exc:
            warnings.append(f"Error reading to.txt: {exc}")
    
    # Check filter.txt + inventory.csv combination
    filter_file = base_folder / "filter.txt"
    if filter_file.is_file():
        if INVENTORY_PATH.is_file():
            try:
                filters = [f.strip() for f in read_file(filter_file).splitlines() 
                          if f.strip() and not f.strip().startswith('#')]
                if filters:
                    # Validate filter syntax and field names
                    is_valid, validation_errors = validate_fields_with_priority(base_folder, "single")
                    if is_valid:
                        # Test filter logic to see how many recipients it would generate
                        test_recipients = apply_filter_logic(filters, INVENTORY_PATH)
                        if test_recipients:
                            recipient_sources["filter.txt + inventory.csv"] = len(test_recipients)
                            log_and_print("info", f"‚úì filter.txt + inventory.csv would generate {len(test_recipients)} recipient(s)")
                        else:
                            warnings.append("filter.txt exists but generates no recipients with current inventory.csv")
                    else:
                        # Include detailed filter validation errors
                        errors.extend([f"filter.txt validation: {error}" for error in validation_errors])
                else:
                    warnings.append("filter.txt exists but contains no active filter conditions")
            except Exception as exc:
                warnings.append(f"Error validating filter.txt: {exc}")
        else:
            warnings.append("filter.txt found but inventory.csv missing at /notifybot/inventory/inventory.csv")
    
    # Check additional_to.txt
    additional_to_file = base_folder / "additional_to.txt"
    if additional_to_file.is_file():
        try:
            additional_emails = read_recipients(additional_to_file)
            if additional_emails:
                recipient_sources["additional_to.txt"] = len(additional_emails)
                log_and_print("info", f"‚úì additional_to.txt found with {len(additional_emails)} recipient(s)")
            else:
                warnings.append("additional_to.txt exists but contains no valid email addresses")
        except Exception as exc:
            warnings.append(f"Error reading additional_to.txt: {exc}")
    
    # Check CC recipients
    cc_file = base_folder / "cc.txt"
    if cc_file.is_file():
        try:
            cc_emails = read_recipients(cc_file)
            if cc_emails:
                recipient_sources["cc.txt"] = len(cc_emails)
                log_and_print("info", f"‚úì cc.txt found with {len(cc_emails)} recipient(s)")
            else:
                warnings.append("cc.txt exists but contains no valid email addresses")
        except Exception as exc:
            warnings.append(f"Error reading cc.txt: {exc}")
    
    # Check BCC recipients
    bcc_file = base_folder / "bcc.txt"
    if bcc_file.is_file():
        try:
            bcc_emails = read_recipients(bcc_file)
            if bcc_emails:
                recipient_sources["bcc.txt"] = len(bcc_emails)
                log_and_print("info", f"‚úì bcc.txt found with {len(bcc_emails)} recipient(s)")
            else:
                warnings.append("bcc.txt exists but contains no valid email addresses")
        except Exception as exc:
            warnings.append(f"Error reading bcc.txt: {exc}")
    
    # Validate that at least one recipient source exists
    if not recipient_sources:
        errors.append(
            "No valid recipient sources found. Single mode requires at least one of:\n"
            "  - to.txt (primary recipients)\n"
            "  - filter.txt + inventory.csv (filtered recipients)\n"
            "  - additional_to.txt (additional recipients)\n"
            "  - cc.txt (CC recipients)\n"
            "  - bcc.txt (BCC recipients)"
        )
    else:
        total_recipients = sum(recipient_sources.values())
        source_names = ", ".join(recipient_sources.keys())
        log_and_print("info", f"‚úì Found {len(recipient_sources)} recipient source(s): {source_names}")
        log_and_print("info", f"‚úì Total recipients across all sources: {total_recipients}")
    
    # 3. EMAIL ADDRESS VALIDATION
    from_file = base_folder / "from.txt"
    if from_file.is_file():
        try:
            from_address = read_file(from_file)
            if from_address:
                if not is_valid_email(from_address):
                    errors.append(f"Invalid sender email address in from.txt: {from_address}")
                else:
                    log_and_print("info", f"‚úì Valid sender email: {from_address}")
            else:
                errors.append("from.txt is empty")
        except Exception as exc:
            errors.append(f"Error reading from.txt: {exc}")
    
    # Validate approver emails for dry-run mode
    approver_file = base_folder / "approver.txt"
    if dry_run:
        if not approver_file.is_file():
            errors.append("approver.txt is required for dry-run mode")
        else:
            try:
                approver_emails = read_recipients(approver_file)
                if not approver_emails:
                    errors.append("approver.txt exists but contains no valid email addresses")
                else:
                    log_and_print("info", f"‚úì Dry-run mode: Found {len(approver_emails)} approver(s)")
            except Exception as exc:
                errors.append(f"Error reading approver.txt for dry-run mode: {exc}")
    else:
        if approver_file.is_file():
            log_and_print("info", "‚úì approver.txt found (not needed for live mode)")
    
    # 4. OPTIONAL COMPONENTS VALIDATION
    
    # Check attachment folder
    attachment_folder = base_folder / "attachment"
    if attachment_folder.exists():
        try:
            check_attachment_size_limit(attachment_folder)
            attachment_count = len([f for f in attachment_folder.iterdir() if f.is_file()])
            if attachment_count > 0:
                log_and_print("info", f"‚úì Found {attachment_count} attachment(s), size check passed")
            else:
                warnings.append("attachment folder exists but is empty")
        except Exception as exc:
            errors.append(f"Attachment validation failed: {exc}")
    else:
        log_and_print("info", "No attachment folder found (optional)")
    
    # Check images folder for email embedding
    images_folder = base_folder / "images"
    if images_folder.exists():
        image_count = len([f for f in images_folder.iterdir() 
                          if f.is_file() and f.suffix.lower() in {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}])
        if image_count > 0:
            log_and_print("info", f"‚úì Found {image_count} image(s) for email embedding")
        else:
            warnings.append("images folder exists but contains no image files")
    else:
        log_and_print("info", "No images folder found (optional)")
    
    # Check for signature
    signature_file = NOTIFYBOT_ROOT / "signature.html"
    if signature_file.is_file():
        try:
            signature_content = signature_file.read_text(encoding="utf-8").strip()
            if signature_content:
                log_and_print("info", f"‚úì Email signature found ({len(signature_content)} characters)")
            else:
                warnings.append("signature.html exists but is empty")
        except Exception as exc:
            warnings.append(f"Error reading signature.html: {exc}")
    else:
        log_and_print("info", "No email signature found (optional)")
    
    # 5. CONTENT VALIDATION
    
    # Validate HTML structure in body.html
    body_file = base_folder / "body.html"
    if body_file.is_file():
        try:
            body_content = read_file(body_file)
            if body_content:
                # Check for basic HTML structure
                if not any(tag in body_content.lower() for tag in ['<html>', '<body>', '<p>', '<div>', '<br>']):
                    warnings.append("body.html doesn't appear to contain HTML tags - consider using HTML formatting")
                
                # Check for potential image references
                if 'src=' in body_content:
                    log_and_print("info", "‚úì body.html contains image references - will attempt to embed images")
                
                # Check for placeholder syntax if field.txt exists
                field_file = base_folder / "field.txt"
                if field_file.is_file():
                    placeholders = re.findall(r'\{([^}]+)\}', body_content)
                    if placeholders:
                        log_and_print("info", f"‚úì Found {len(set(placeholders))} placeholder(s) in body.html: {', '.join(set(placeholders))}")
                    else:
                        warnings.append("field.txt exists but body.html contains no {field} placeholders")
        except Exception as exc:
            errors.append(f"Error validating body.html: {exc}")
    
    # 6. INTEGRATION WARNINGS AND SUGGESTIONS
    
    # Check for potential field.txt usage
    field_file = base_folder / "field.txt"
    if field_file.is_file():
        if not filter_file.is_file():
            warnings.append("field.txt found but filter.txt missing - field substitution requires filters")
        else:
            log_and_print("info", "‚úì field.txt found - template substitution will be available if filters are used")
    
    # Check for mode.txt file
    mode_file = base_folder / "mode.txt"
    if mode_file.is_file():
        try:
            mode_content = mode_file.read_text(encoding="utf-8").strip().lower()
            if mode_content == "single":
                log_and_print("info", "‚úì mode.txt confirms single mode operation")
            elif mode_content == "multi":
                warnings.append("mode.txt specifies 'multi' but single mode validation requested - check mode configuration")
            else:
                warnings.append(f"mode.txt contains invalid mode '{mode_content}' - should be 'single' or 'multi'")
        except Exception as exc:
            warnings.append(f"Error reading mode.txt: {exc}")
    
    # 7. FINAL VALIDATION SUMMARY
    
    # Log all warnings
    if warnings:
        log_and_print("warning", f"Found {len(warnings)} warning(s):")
        for warning in warnings:
            log_and_print("warning", f"  ‚Ä¢ {warning}")
    
    # Check for errors and raise exception if any found
    if errors:
        log_and_print("error", f"Single mode validation failed with {len(errors)} error(s):")
        for error in errors:
            log_and_print("error", f"  ‚úó {error}")
        
        # Provide helpful suggestions
        if not recipient_sources:
            log_and_print("info", "SUGGESTION: Create at least one recipient file:")
            log_and_print("info", "  ‚Ä¢ to.txt - Main recipient list (one email per line)")
            log_and_print("info", "  ‚Ä¢ cc.txt - CC recipients (optional)")
            log_and_print("info", "  ‚Ä¢ bcc.txt - BCC recipients (optional)")
            log_and_print("info", "  ‚Ä¢ filter.txt + inventory.csv - Dynamic recipients based on filters")
        
        raise MissingRequiredFilesError(
            f"Single mode validation failed. {len(errors)} error(s) found. "
            "Please check the log messages above for specific issues."
        )
    
    # Success message
    sources_summary = f"{len(recipient_sources)} recipient source(s)" if recipient_sources else "0 recipient sources"
    total_recipients = sum(recipient_sources.values()) if recipient_sources else 0
    
    log_and_print("success", f"‚úÖ Single mode validation passed!")
    log_and_print("success", f"‚úÖ Configuration: {sources_summary}, {total_recipients} total recipient(s)")
    if warnings:
        log_and_print("info", f"Note: {len(warnings)} warning(s) found but validation passed")


def print_single_mode_help():
    """Print detailed help for single mode requirements and file formats."""
    help_text = """
SINGLE MODE REQUIREMENTS GUIDE
==============================

REQUIRED FILES:
--------------
‚Ä¢ subject.txt     - Email subject line (one line)
‚Ä¢ body.html       - Email body content in HTML format  
‚Ä¢ from.txt        - Sender email address (one line)
‚Ä¢ approver.txt    - Approver emails for dry-run mode (one per line or semicolon-separated)

RECIPIENT FILES (at least one required):
---------------------------------------
‚Ä¢ to.txt          - Primary recipients (one per line or semicolon-separated)
‚Ä¢ cc.txt          - CC recipients (optional)
‚Ä¢ bcc.txt         - BCC recipients (optional)  
‚Ä¢ additional_to.txt - Additional recipients to merge with main list
‚Ä¢ filter.txt      - Filter conditions (requires inventory.csv)

OPTIONAL FILES:
--------------
‚Ä¢ mode.txt        - Force mode to 'single' (overrides auto-detection)
‚Ä¢ field.txt       - Field names for template substitution (requires filter.txt)
‚Ä¢ signature.html  - Email signature (global file at /notifybot/signature.html)

OPTIONAL FOLDERS:
----------------
‚Ä¢ attachment/     - Files to attach to emails (15MB total limit)
‚Ä¢ images/         - Images to embed in HTML emails (JPG, PNG, GIF, BMP)

EXAMPLE FILE CONTENTS:
---------------------

subject.txt:
    Weekly Project Update

body.html:
    <html>
    <body>
    <h1>Hello {name}!</h1>
    <p>Your department: {department}</p>
    <img src="logo.png" alt="Logo">
    </body>
    </html>

from.txt:
    sender@company.com

to.txt:
    user1@company.com
    user2@company.com; user3@company.com

filter.txt:
    department=Engineering
    status=Active,role=~.*Manager.*

field.txt:
    name
    department
    role

VALIDATION CHECKS:
-----------------
‚úì All required files exist and have content
‚úì At least one recipient source is configured  
‚úì Email addresses are properly formatted
‚úì Filter syntax is valid (if using filters)
‚úì Attachment size under 15MB limit
‚úì Images exist for embedding (if referenced)
‚úì HTML structure is valid
‚úì Field placeholders match field.txt (if used)
"""
    print(help_text)


def perform_field_validation(base: Path, mode: str) -> List[str]:
    """Perform field validation using the existing priority-based validation system."""
    try:
        is_valid, validation_errors = validate_fields_with_priority(base, mode)
        
        if is_valid:
            log_and_print("success", "Field validation passed - all field names are valid")
            return []
        else:
            log_and_print("error", "Field validation failed:")
            for error in validation_errors:
                log_and_print("error", f"  {error}")
            return validation_errors
            
    except Exception as exc:
        error_msg = f"Field validation encountered an error: {exc}"
        log_and_print("error", error_msg)
        return [error_msg]


def validate_optional_files(base: Path, mode: str) -> List[str]:
    """Validate optional files and return warnings for potential issues."""
    warnings = []
    
    # Check for mode.txt
    mode_file = base / "mode.txt"
    if mode_file.is_file():
        try:
            mode_content = mode_file.read_text(encoding="utf-8").strip().lower()
            if mode_content in ['single', 'multi']:
                log_and_print("info", f"Found mode.txt specifying '{mode_content}' mode")
                if mode_content != mode.lower():
                    warnings.append(f"mode.txt specifies '{mode_content}' but running in '{mode}' mode (CLI override)")
            else:
                warnings.append(f"mode.txt contains invalid mode '{mode_content}' (should be 'single' or 'multi')")
        except Exception as exc:
            warnings.append(f"Cannot read mode.txt: {exc}")
    
    # Check for field.txt in single mode (informational)
    field_file = base / "field.txt"
    if mode == "single" and field_file.is_file():
        warnings.append("field.txt found in single mode (will be ignored - only used in multi mode)")
    elif mode == "multi" and field_file.is_file():
        try:
            field_content = field_file.read_text(encoding="utf-8").strip()
            if field_content:
                field_count = len([line.strip() for line in field_content.splitlines() if line.strip()])
                log_and_print("info", f"Found field.txt with {field_count} field(s) for template substitution")
            else:
                warnings.append("field.txt exists but is empty")
        except Exception as exc:
            warnings.append(f"Cannot read field.txt: {exc}")
    
    # Check for table-columns.txt
    table_columns_file = base / "table-columns.txt"
    if table_columns_file.is_file():
        try:
            table_content = table_columns_file.read_text(encoding="utf-8").strip()
            if table_content:
                column_count = len([line.strip() for line in table_content.splitlines() if line.strip()])
                log_and_print("info", f"Found table-columns.txt with {column_count} column(s) for dynamic tables")
            else:
                warnings.append("table-columns.txt exists but is empty")
        except Exception as exc:
            warnings.append(f"Cannot read table-columns.txt: {exc}")
    
    # Check for images folder
    images_folder = base / "images"
    if images_folder.exists():
        if images_folder.is_dir():
            try:
                image_files = [f for f in images_folder.iterdir() if f.is_file()]
                if image_files:
                    log_and_print("info", f"Found images folder with {len(image_files)} file(s)")
                else:
                    warnings.append("images folder exists but is empty")
            except Exception as exc:
                warnings.append(f"Cannot access images folder: {exc}")
        else:
            warnings.append("images path exists but is not a directory")
    
    # Check for local field-inventory.csv
    local_inventory = base / "field-inventory.csv"
    if local_inventory.is_file():
        try:
            with open(local_inventory, mode="r", newline="", encoding="utf-8") as file:
                reader = csv.DictReader(file)
                local_fields = reader.fieldnames or []
                if local_fields:
                    log_and_print("info", f"Found local field-inventory.csv with {len(local_fields)} field(s) (takes priority over global)")
                else:
                    warnings.append("local field-inventory.csv exists but has no headers")
        except Exception as exc:
            warnings.append(f"Cannot read local field-inventory.csv: {exc}")
    
    return warnings


def provide_validation_suggestions(base: Path, mode: str, errors: List[str]) -> None:
    """Provide helpful suggestions based on validation errors."""
    log_and_print("info", "Validation suggestions:")
    
    # Analyze errors and provide specific suggestions
    missing_files = [error for error in errors if "Missing required file" in error]
    field_errors = [error for error in errors if "Field" in error and ("not found" in error or "validation" in error)]
    recipient_errors = [error for error in errors if "recipient" in error.lower()]
    
    if missing_files:
        log_and_print("info", "For missing files:")
        log_and_print("info", f"  - Ensure all required files exist in {base}")
        log_and_print("info", "  - Check file names for typos (case-sensitive)")
        log_and_print("info", "  - Verify file permissions allow reading")
    
    if field_errors:
        log_and_print("info", "For field validation errors:")
        log_and_print("info", "  - Check field names in filter.txt, field.txt, and table-columns.txt")
        log_and_print("info", "  - Verify field names exist in inventory.csv headers")
        log_and_print("info", "  - Remove extra whitespace from field names")
        log_and_print("info", "  - Use local field-inventory.csv if you need custom fields")
    
    if recipient_errors:
        log_and_print("info", "For recipient source errors:")
        if mode == "single":
            log_and_print("info", "  - Create to.txt with recipient email addresses, OR")
            log_and_print("info", "  - Create filter.txt with conditions + ensure inventory.csv exists, OR") 
            log_and_print("info", "  - Create cc.txt, bcc.txt, or additional_to.txt with recipients")
        else:
            log_and_print("info", "  - Ensure filter.txt has valid filter conditions")
            log_and_print("info", f"  - Verify inventory.csv exists at {INVENTORY_PATH}")
    
    log_and_print("info", f"Run with --dry-run first to test your configuration safely")



class MissingRequiredFilesError(Exception):
    """Exception raised when required input files are missing."""

def validate_base_folder(base_folder: str) -> Path:
    """Ensure that the base folder is a valid relative path inside /notifybot/basefolder"""
    base_folder_path = BASEFOLDER_PATH / base_folder
    
    # Ensure the base folder is inside /notifybot/basefolder
    if not base_folder_path.is_dir():
        raise ValueError(f"Invalid base folder: {base_folder}. It must be a directory inside '/notifybot/basefolder'.")

    # Return the validated path
    return base_folder_path

def csv_log_entry(message: str) -> str:
    """Generate log entry in CSV format with proper escaping."""
    timestamp_epoch = time.time_ns() // 1_000_000  # Nanoseconds to milliseconds
    try:
        username = os.getlogin()  # Get the username of the executor
    except OSError:
        # Fallback for environments where getlogin() fails
        username = os.getenv('USER', os.getenv('USERNAME', 'unknown'))
    
    # Use csv.writer to properly escape the message field
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow([timestamp_epoch, username, message])
    csv_line = output.getvalue().strip()  # Remove trailing newline
    output.close()
    
    return csv_line

def setup_logging() -> None:
    """Configure logging to INFO+ level in LOG_FILENAME with structured CSV format."""
    # Ensure log directory exists
    LOG_FILENAME.parent.mkdir(parents=True, exist_ok=True)
    
    # Configure logging
    logging.basicConfig(
        filename=LOG_FILENAME,
        level=logging.INFO,
        format='%(message)s',
        filemode='a'
    )
    
    def log_and_print(level: str, message: str) -> None:
        """Log and color-print a message at INFO/WARNING/ERROR levels in CSV format."""
        # Emoji mappings for log levels
        emoji_mapping = {
            "info": "‚ÑπÔ∏è",
            "warning": "‚ö†Ô∏è",
            "error": "‚ùå",
            "success": "‚úÖ",
            "processing": "‚è≥",
            "backup": "üíæ",
            "file": "üìÇ",
            "confirmation": "‚úã",
            "draft": "üìù",
            "mode": "üîß",
            "signature": "‚úçÔ∏è"
        }

        # Get emoji for level
        emoji = emoji_mapping.get(level.lower(), "")
        csv_log = csv_log_entry(f"{emoji} {message}")
        log_func = getattr(logging, level.lower(), logging.info)
        log_func(csv_log)
        print(f"{csv_log}")  # Print to the console as well

    globals()['log_and_print'] = log_and_print

def determine_mode(base_folder: Path, cli_mode: str = None) -> str:
    """
    Determine operating mode with priority: CLI > mode.txt > default (single)
    """
    # Priority 1: CLI override
    if cli_mode and cli_mode.lower() in ['single', 'multi']:
        mode = cli_mode.lower()
        log_and_print("mode", f"Mode determined by CLI argument: {mode}")
        return mode
    
    # Priority 2: mode.txt file
    mode_file = base_folder / "mode.txt"
    if mode_file.is_file():
        try:
            mode_content = mode_file.read_text(encoding="utf-8").strip().lower()
            if mode_content in ['single', 'multi']:
                log_and_print("mode", f"Mode determined by mode.txt: {mode_content}")
                return mode_content
            else:
                log_and_print("warning", f"Invalid mode in mode.txt: {mode_content}. Using default 'single'")
        except Exception as exc:
            log_and_print("warning", f"Error reading mode.txt: {exc}. Using default 'single'")
    
    # Priority 3: Default
    log_and_print("mode", "Mode defaulted to: single")
    return "single"

def read_signature() -> str:
    """
    """
    # Changed to use global signature location
    signature_file = NOTIFYBOT_ROOT / "signature.html"  # /notifybot/signature.html
    
    if not signature_file.is_file():
        log_and_print("info", "No signature.html found at /notifybot/signature.html, emails will be sent without signature")
        return ""
    
    try:
        signature_content = signature_file.read_text(encoding="utf-8").strip()
        if signature_content:
            log_and_print("signature", f"Loaded signature from /notifybot/signature.html ({len(signature_content)} characters)")
            return signature_content
        else:
            log_and_print("warning", "/notifybot/signature.html is empty")
            return ""
    except Exception as exc:
        log_and_print("error", f"Failed to read /notifybot/signature.html: {exc}")
        return ""

def combine_body_and_signature(body_html: str, signature_html: str) -> str:
    """
    """
    if not signature_html:
        return body_html
    
    # Add signature separator and signature
    signature_separator = "\n<br><br>\n"  # Add some spacing before signature
    combined_html = body_html + signature_separator + signature_html
    
    log_and_print("signature", "Combined body and signature successfully")
    return combined_html

def find_sendmail_path() -> str:
    """Find sendmail executable path."""
    common_paths = [
        '/usr/sbin/sendmail',
        '/usr/bin/sendmail',
        '/sbin/sendmail',
        '/usr/lib/sendmail'
    ]
    
    for path in common_paths:
        if Path(path).exists():
            return path
    
    # Try to find in PATH
    try:
        result = subprocess.run(['which', 'sendmail'], capture_output=True, text=True)
        if result.returncode == 0:
            return result.stdout.strip()
    except:
        pass
    
    log_and_print("warning", "Sendmail not found in common locations")
    return '/usr/sbin/sendmail'  # Default fallback

def is_valid_email(email: str) -> bool:
    """Check email syntax using email_validator with sendmail compatibility."""
    try:
        validate_email(email.strip(), check_deliverability=False)
        
        # Additional checks for sendmail compatibility
        email = email.strip()
        if len(email) > 320:  # RFC 5321 limit
            log_and_print("warning", f"Email too long (>320 chars): {email}")
            return False
        
        # Check for characters that might cause issues with sendmail
        problematic_chars = ['|', '`', '$', '\\']
        if any(char in email for char in problematic_chars):
            log_and_print("warning", f"Email contains potentially problematic characters: {email}")
            return False
        
        return True
    except EmailNotValidError as exc:
        log_and_print("error", f"Invalid email format: {email}. Error: {exc}")
        return False

def read_file(path: Path) -> str:
    """Read text file content and strip, or log an error."""
    try:
        return path.read_text(encoding="utf-8").strip()
    except Exception as exc:
        log_and_print("error", f"Failed to read {path}: {exc}")
        return ""

def extract_emails(raw: str, delimiters: str = ";") -> List[str]:
    """Split and trim emails from a raw string by delimiters."""
    if not raw:
        return []
    return [e.strip() for e in re.split(f"[{re.escape(delimiters)}]", raw) if e.strip()]

def read_recipients(path: Path, delimiters: str = ";") -> List[str]:
    """Read and validate emails from a file (semicolon-separated)."""
    valid = []
    if not path.is_file():
        log_and_print("warning", f"{path.name} missing, skipping.")
        return valid
    
    try:
        for line in path.read_text(encoding="utf-8").splitlines():
            for email in extract_emails(line.strip(), delimiters):
                if is_valid_email(email):
                    valid.append(email)
                else:
                    log_and_print("warning", f"Invalid email skipped: {email}")
    except Exception as exc:
        log_and_print("error", f"Error processing recipients in {path}: {exc}")
    return valid

def deduplicate_emails(emails: List[str]) -> List[str]:
    """Deduplicate email addresses (case-insensitive) while preserving order."""
    seen = set()
    unique_emails = []
    for email in emails:
        email_lower = email.lower()
        if email_lower not in seen:
            seen.add(email_lower)
            unique_emails.append(email)
    return unique_emails

def write_recipients_to_file(path: Path, recipients: List[str]) -> None:
    """Write recipients list to a file, one per line, with deduplication."""
    try:
        # Deduplicate recipients
        unique_recipients = deduplicate_emails(recipients)
        
        with path.open('w', encoding='utf-8') as f:
            for email in unique_recipients:
                f.write(f"{email}\n")
        
        if len(recipients) != len(unique_recipients):
            duplicates_removed = len(recipients) - len(unique_recipients)
            log_and_print("info", f"Removed {duplicates_removed} duplicate email(s)")
        
        log_and_print("file", f"Written {len(unique_recipients)} unique recipients to {path.name}")
    except Exception as exc:
        log_and_print("error", f"Error writing recipients to {path}: {exc}")

def merge_recipients(base_recipients: List[str], additional_recipients: List[str]) -> List[str]:
    """Merge two lists of recipients, removing duplicates while preserving order."""
    # Combine all recipients and deduplicate
    all_recipients = base_recipients + additional_recipients
    return deduplicate_emails(all_recipients)


def sanitize_filename(filename: str) -> str:
    """Sanitize the filename to prevent issues with special characters."""
    return re.sub(r"[^\w\s.-]", "", filename)

def add_attachments(msg: MIMEMultipart, attachment_folder: Path) -> None:
    """Add all files from attachment folder to the email message."""
    if not attachment_folder or not attachment_folder.exists():
        return
        
    try:
        for file_path in attachment_folder.iterdir():
            if file_path.is_file():
                # Get MIME type
                ctype, encoding = mimetypes.guess_type(str(file_path))
                if ctype is None or encoding is not None:
                    ctype = 'application/octet-stream'
                
                maintype, subtype = ctype.split('/', 1)
                
                with open(file_path, 'rb') as fp:
                    attachment = MIMEBase(maintype, subtype)
                    attachment.set_payload(fp.read())
                    encoders.encode_base64(attachment)
                    attachment.add_header(
                        'Content-Disposition',
                        f'attachment; filename="{sanitize_filename(file_path.name)}"'
                    )
                    msg.attach(attachment)
                
                log_and_print("info", f"Attached file: {file_path.name}")
                
    except Exception as exc:
        log_and_print("error", f"Error adding attachments: {exc}")

def create_email_message(recipients: List[str], subject: str, body_html: str, 
                        from_address: str, attachment_folder: Path = None,
                        base_folder: Path = None, cc_recipients: List[str] = None,
                        bcc_recipients: List[str] = None) -> MIMEMultipart:
    """Create a properly formatted email message with embedded images and attachments."""
    cc_recipients = cc_recipients or []
    bcc_recipients = bcc_recipients or []
    
    # Embed images if base_folder is provided
    embedded_images = []
    if base_folder:
        body_html, embedded_images = embed_images_in_html(body_html, base_folder)
    
    # Create multipart message
    if embedded_images:
        msg = MIMEMultipart('related')  # Use 'related' when we have embedded images
    else:
        msg = MIMEMultipart('mixed')    # Use 'mixed' for attachments only
    
    msg['From'] = from_address
    msg['To'] = ', '.join(recipients)
    if cc_recipients:
        msg['Cc'] = ', '.join(cc_recipients)
        log_and_print("info", f"CC: {len(cc_recipients)} recipient(s)")
       
    # Note: BCC headers are intentionally NOT added to prevent recipients from seeing BCC list
    if bcc_recipients:
        log_and_print("info", f"BCC: {len(bcc_recipients)} recipient(s)")
       
    msg['Subject'] = subject
    
    # Create multipart alternative for HTML content if we have embedded images
    if embedded_images:
        msg_alternative = MIMEMultipart('alternative')
        msg.attach(msg_alternative)
        
        # Add HTML body to alternative
        html_part = MIMEText(body_html, 'html', 'utf-8')
        msg_alternative.attach(html_part)
        
        # Add embedded images to main message
        for img in embedded_images:
            msg.attach(img)
    else:
        # No embedded images, add HTML directly
        html_part = MIMEText(body_html, 'html', 'utf-8')
        msg.attach(html_part)
    
    # Add attachments if folder exists
    if attachment_folder:
        add_attachments(msg, attachment_folder)
    
    return msg


def matches_filter_conditions(row: Dict, filters: List[str]) -> bool:
    """
    """
    if not filters:
        return True  # No filters means include all
    
    def matches_exact(text: str, pattern: str) -> bool:
        """Exact string match (case-insensitive)."""
        return str(text).lower() == pattern.lower()
    
    def matches_not_equal(text: str, pattern: str) -> bool:
        """Not equal match (case-insensitive)."""
        return str(text).lower() != pattern.lower()
    
    def matches_regex(text: str, pattern: str) -> bool:
        """Regex match (case-insensitive)."""
        try:
            return bool(re.search(pattern, str(text), re.IGNORECASE))
        except re.error as e:
            print(f"Invalid regex pattern '{pattern}': {e}")
            return False
    
    def matches_regex_not(text: str, pattern: str) -> bool:
        """Regex not match (case-insensitive)."""
        try:
            return not bool(re.search(pattern, str(text), re.IGNORECASE))
        except re.error as e:
            print(f"Invalid regex pattern '{pattern}': {e}")
            return False
    
    def matches_wildcard(text: str, pattern: str) -> bool:
        """Wildcard match using fnmatch (case-insensitive)."""
        return fnmatch.fnmatch(str(text).lower(), pattern.lower())
    
    def parse_condition(condition: str) -> tuple:
        """
        """
        condition = condition.strip()
        
        # Check for regex operators first (longer patterns)
        if '=~' in condition:
            key, value = condition.split('=~', 1)
            return key.strip(), '=~', value.strip().strip('"\'')
        elif '!~' in condition:
            key, value = condition.split('!~', 1)
            return key.strip(), '!~', value.strip().strip('"\'')
        elif '!=' in condition:
            key, value = condition.split('!=', 1)
            return key.strip(), '!=', value.strip().strip('"\'')
        elif '=' in condition:
            key, value = condition.split('=', 1)
            value = value.strip().strip('"\'')
            # Check if value contains wildcards
            if '*' in value or '?' in value or '[' in value:
                return key.strip(), '*', value
            else:
                return key.strip(), '=', value
        else:
            # Simple wildcard search in all values (backward compatibility)
            return None, '*', condition
    
    def evaluate_condition(key: str, operator: str, value: str, row: Dict) -> bool:
        """Evaluate a single condition against a row."""
        if key is None:
            # Simple wildcard search in all values (backward compatibility)
            for row_value in row.values():
                if matches_wildcard(row_value, value):
                    return True
            return False
        
        if key not in row:
            return False  # Key doesn't exist in row
        
        row_value = row[key]
        
        if operator == '=':
            return matches_exact(row_value, value)
        elif operator == '!=':
            return matches_not_equal(row_value, value)
        elif operator == '=~':
            return matches_regex(row_value, value)
        elif operator == '!~':
            return matches_regex_not(row_value, value)
        elif operator == '*':
            return matches_wildcard(row_value, value)
        else:
            return False
    
    # Process each line as a separate OR condition
    for filter_line in filters:
        filter_line = filter_line.strip()
        
        # Skip empty lines and comments
        if not filter_line or filter_line.startswith('#'):
            continue
        
        # Split the line into individual AND conditions
        and_conditions = [condition.strip() for condition in filter_line.split(',')]
        
        # Check if ALL conditions in this line match (AND logic)
        line_matches = True
        for condition in and_conditions:
            if not condition:
                continue
            
            try:
                key, operator, value = parse_condition(condition)
                if not evaluate_condition(key, operator, value, row):
                    line_matches = False
                    break  # This AND condition failed
            except Exception as e:
                print(f"Error parsing condition '{condition}': {e}")
                line_matches = False
                break
        
        # If this line matched completely (all AND conditions), return True (OR logic)
        if line_matches:
            return True
    
    # None of the OR conditions matched
    return False

def validate_filter_syntax(filters: List[str], available_fields: Set[str] = None) -> Tuple[bool, List[str]]:
    """
    """
    errors = []
    
    for i, filter_line in enumerate(filters, 1):
        filter_line = filter_line.strip()
        
        # Skip comments and empty lines
        if not filter_line or filter_line.startswith('#'):
            continue
        
        # Split into AND conditions
        and_conditions = [condition.strip() for condition in filter_line.split(',')]
        
        for condition in and_conditions:
            if not condition:
                continue
            
            # Check for valid operators
            valid_operators = ['=~', '!~', '!=', '=']
            has_valid_operator = False
            field_name = None
            
            for op in valid_operators:
                if op in condition:
                    has_valid_operator = True
                    parts = condition.split(op, 1)
                    if len(parts) != 2:
                        errors.append(f"Line {i}: Invalid condition syntax '{condition}'")
                        break
                    
                    field_name, value = parts[0].strip(), parts[1].strip()
                    
                    if not field_name:
                        errors.append(f"Line {i}: Empty field name in '{condition}'")
                    
                    if not value:
                        errors.append(f"Line {i}: Empty value in '{condition}'")
                    
                    # NEW: Check if field exists in available fields
                    if available_fields and field_name and field_name not in available_fields:
                        errors.append(f"Line {i}: Field '{field_name}' not found in inventory.csv headers")
                    
                    # Validate regex patterns for regex operators
                    if op in ['=~', '!~']:
                        value_clean = value.strip('"\'')
                        try:
                            re.compile(value_clean)
                        except re.error as e:
                            errors.append(f"Line {i}: Invalid regex pattern '{value_clean}': {e}")
                    
                    break
            
            if not has_valid_operator:
                # Check if it's a simple wildcard pattern (backward compatibility)
                if not ('*' in condition or '?' in condition or '[' in condition):
                    errors.append(f"Line {i}: No valid operator found in '{condition}'. Use =, !=, =~, !~, or wildcards (*,?,[])")
    
    return len(errors) == 0, errors


def print_filter_syntax_help() -> None:
    """
    Display comprehensive filter syntax help and examples.
    This function provides guidance on how to write filter.txt conditions.
    """
    log_and_print("info", "FILTER SYNTAX HELP:")
    log_and_print("info", "=" * 50)
    
    # Basic syntax
    log_and_print("info", "BASIC SYNTAX:")
    log_and_print("info", "  field_name = 'exact_value'        # Exact match (case-insensitive)")
    log_and_print("info", "  field_name != 'not_this_value'    # Not equal match")
    log_and_print("info", "  field_name =~ 'regex_pattern'     # Regex match") 
    log_and_print("info", "  field_name !~ 'regex_pattern'     # Regex NOT match")
    log_and_print("info", "  field_name = 'value*'             # Wildcard match (* ? [])")
    log_and_print("info", "")
    
    # AND logic
    log_and_print("info", "AND LOGIC (comma-separated on same line):")
    log_and_print("info", "  department = 'IT', status = 'active'")
    log_and_print("info", "  role =~ 'manager|director', location != 'remote'")
    log_and_print("info", "")
    
    # OR logic  
    log_and_print("info", "OR LOGIC (separate lines):")
    log_and_print("info", "  department = 'IT'")
    log_and_print("info", "  department = 'Engineering'") 
    log_and_print("info", "  department = 'DevOps'")
    log_and_print("info", "")
    
    # Complex examples
    log_and_print("info", "COMPLEX EXAMPLES:")
    log_and_print("info", "  # All IT staff who are active")
    log_and_print("info", "  department = 'IT', status = 'active'")
    log_and_print("info", "")
    log_and_print("info", "  # Managers or Directors in any department")
    log_and_print("info", "  role =~ 'manager|director'")
    log_and_print("info", "")
    log_and_print("info", "  # Active users NOT in HR department")
    log_and_print("info", "  status = 'active', department != 'HR'")
    log_and_print("info", "")
    log_and_print("info", "  # Users with email containing 'admin'")
    log_and_print("info", "  email =~ '.*admin.*'")
    log_and_print("info", "")
    log_and_print("info", "  # Wildcard: all departments starting with 'Tech'")
    log_and_print("info", "  department = 'Tech*'")
    log_and_print("info", "")
    
    # Regex examples
    log_and_print("info", "REGEX PATTERN EXAMPLES:")
    log_and_print("info", "  email =~ '.*@company\\.com$'       # Emails ending with @company.com")
    log_and_print("info", "  phone =~ '^\\+1'                  # Phone numbers starting with +1") 
    log_and_print("info", "  name =~ '^(John|Jane)'            # Names starting with John or Jane")
    log_and_print("info", "  id =~ '^[0-9]{4}$'               # 4-digit numeric IDs")
    log_and_print("info", "")
    
    # Wildcard examples
    log_and_print("info", "WILDCARD PATTERN EXAMPLES:")
    log_and_print("info", "  name = 'John*'                    # Names starting with 'John'")
    log_and_print("info", "  email = '*@gmail.com'             # Gmail addresses")
    log_and_print("info", "  department = 'Tech*'              # Departments starting with 'Tech'")
    log_and_print("info", "  role = '*manager'                 # Roles ending with 'manager'")
    log_and_print("info", "  code = 'A??B'                     # 4-char codes: A + 2 chars + B")
    log_and_print("info", "")
    
    # Comments and organization
    log_and_print("info", "COMMENTS & ORGANIZATION:")
    log_and_print("info", "  # This is a comment - ignored by filter")
    log_and_print("info", "  # You can use comments to organize your filters")
    log_and_print("info", "  ")
    log_and_print("info", "  # Active IT staff")
    log_and_print("info", "  department = 'IT', status = 'active'")
    log_and_print("info", "  ")
    log_and_print("info", "  # Management team")
    log_and_print("info", "  role =~ 'manager|director|VP'")
    log_and_print("info", "")
    
    # Important notes
    log_and_print("info", "IMPORTANT NOTES:")
    log_and_print("info", "  ‚Ä¢ Each line is an OR condition")
    log_and_print("info", "  ‚Ä¢ Comma-separated conditions on same line are AND")
    log_and_print("info", "  ‚Ä¢ String matching is case-insensitive")
    log_and_print("info", "  ‚Ä¢ Field names must exist in inventory.csv")
    log_and_print("info", "  ‚Ä¢ Empty lines and comments (#) are ignored")
    log_and_print("info", "  ‚Ä¢ Regular expressions use Python re module syntax")
    log_and_print("info", "  ‚Ä¢ Wildcard patterns: * (any chars), ? (single char), [] (char class)")
    log_and_print("info", "")
    
    # Common mistakes
    log_and_print("info", "COMMON MISTAKES TO AVOID:")
    log_and_print("info", "  ‚ùå missing = operator: department 'IT'")
    log_and_print("info", "  ‚úÖ correct syntax: department = 'IT'")
    log_and_print("info", "")
    log_and_print("info", "  ‚ùå invalid field name: invalid_field = 'value'")
    log_and_print("info", "  ‚úÖ use valid fields from inventory.csv")
    log_and_print("info", "")
    log_and_print("info", "  ‚ùå bad regex: email =~ '*@company.com'")
    log_and_print("info", "  ‚úÖ correct regex: email =~ '.*@company\\.com$'")
    log_and_print("info", "")
    
    log_and_print("info", "=" * 50)
   

def apply_filter_logic(filters: List[str], inventory_path: Path) -> List[str]:
    """
    """
    filtered_recipients = []
    
    if not inventory_path.exists():
        log_and_print("error", f"Inventory file not found: {inventory_path}")
        return filtered_recipients
    
    # Read available fields from inventory
    try:
        with open(inventory_path, mode="r", newline="", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            available_fields = set(reader.fieldnames or [])
    except Exception as exc:
        log_and_print("error", f"Error reading inventory headers: {exc}")
        return filtered_recipients
    
    # Validate filter syntax WITH field name checking
    is_valid, errors = validate_filter_syntax(filters, available_fields)
    if not is_valid:
        log_and_print("error", "Filter syntax/field validation failed:")
        for error in errors:
            log_and_print("error", f"  {error}")
        print_filter_syntax_help()
        log_and_print("info", f"Available fields in inventory.csv: {', '.join(sorted(available_fields))}")
        return filtered_recipients
    
    # Count total non-comment filter lines for logging
    active_filters = [f.strip() for f in filters if f.strip() and not f.strip().startswith('#')]
    if not active_filters:
        log_and_print("warning", "No active filter conditions found (only comments/empty lines)")
        return filtered_recipients
    
    log_and_print("info", f"Applying {len(active_filters)} filter condition(s) with PromQL-style syntax")
    
    # Log filter conditions for debugging
    for i, filter_line in enumerate(active_filters, 1):
        log_and_print("info", f"Filter {i}: {filter_line}")
    
    try:
        matched_rows = 0
        total_rows = 0
        
        with open(inventory_path, mode="r", newline="", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            
            for row in reader:
                total_rows += 1
                
                if matches_filter_conditions(row, filters):
                    matched_rows += 1
                    
                    if 'email' in row:
                        # Extract and validate each email from semicolon-separated string
                        email_string = row['email']
                        individual_emails = extract_emails(email_string, ";")
                        
                        for email in individual_emails:
                            if is_valid_email(email):
                                filtered_recipients.append(email)
                            else:
                                log_and_print("warning", f"Invalid email skipped: {email}")
                        
                        if not individual_emails:
                            log_and_print("warning", f"Row has empty email field: {row}")
                    else:
                        log_and_print("warning", f"Row missing email column: {row}")
        
        # Deduplicate filtered recipients
        original_count = len(filtered_recipients)
        filtered_recipients = deduplicate_emails(filtered_recipients)
        
        if original_count != len(filtered_recipients):
            log_and_print("info", f"Removed {original_count - len(filtered_recipients)} duplicate emails from filter results")
        
        # Enhanced logging with statistics
        log_and_print("info", f"Filter processing complete:")
        log_and_print("info", f"  - Total rows in inventory: {total_rows}")
        log_and_print("info", f"  - Rows matching filters: {matched_rows}")
        log_and_print("info", f"  - Unique email recipients: {len(filtered_recipients)}")
        
        if matched_rows > 0:
            match_percentage = (matched_rows / total_rows) * 100
            log_and_print("info", f"  - Match rate: {match_percentage:.1f}%")
        
    except Exception as exc:
        log_and_print("error", f"Error applying filter logic: {exc}")
        log_and_print("error", f"Make sure inventory.csv has proper headers and format")
    
    return filtered_recipients

  
        
        
      
    
def substitute_placeholders(template: str, field_values: Dict[str, str]) -> str:
    """
    """
    result = template
    substitutions_made = 0
    
    for field, value in field_values.items():
        placeholder = f"{{{field}}}"
        
        if placeholder in result:
            # Clean up comma-separated values for better readability
            if value and ',' in value:
                # For comma-separated values, format them nicely
                values = [v.strip() for v in value.split(',') if v.strip()]
                if len(values) == 1:
                    clean_value = values[0]
                elif len(values) == 2:
                    clean_value = f"{values[0]} and {values[1]}"
                elif len(values) <= 5:
                    # For small lists, show all with proper formatting
                    clean_value = f"{', '.join(values[:-1])}, and {values[-1]}"
                else:
                    # For large lists, show first few and add "and X more"
                    remaining = len(values) - 3
                    clean_value = f"{', '.join(values[:3])}, and {remaining} more"
            else:
                clean_value = value if value else f"{{{field}}}" # ‚Üê HERE'S THE PROBLEM
            
            # Perform the substitution
            result = result.replace(placeholder, clean_value)
            substitutions_made += 1
    
    # Log substitution details if any were made
    if substitutions_made > 0:
        log_and_print("info", f"Template substitution: {substitutions_made} placeholder(s) replaced")
    
    return result



def get_recipients_for_single_mode(base_folder: Path, dry_run: bool) -> Tuple[List[str], List[str], List[str], int, int, int]:
    """
    Get recipients for single mode operation with improved logic and cleaner code structure.
    
    Returns:
        (final_recipients, final_cc_recipients, final_bcc_recipients, 
         original_recipients_count, original_cc_count, original_bcc_count)
    """
    
    # Initialize recipient containers
    cc_emails = read_recipients(base_folder / "cc.txt")
    bcc_emails = read_recipients(base_folder / "bcc.txt")
    
    # Log CC/BCC counts if present
    if cc_emails:
        log_and_print("info", f"Loaded {len(cc_emails)} CC recipients from cc.txt")
    if bcc_emails:
        log_and_print("info", f"Loaded {len(bcc_emails)} BCC recipients from bcc.txt")
    
    # Store original counts early for consistency
    original_cc_count = len(deduplicate_emails(cc_emails))
    original_bcc_count = len(deduplicate_emails(bcc_emails))
    
    # Define file paths once
    file_paths = {
        'to': base_folder / "to.txt",
        'additional_to': base_folder / "additional_to.txt",
        'filter': base_folder / "filter.txt",
        'approver': base_folder / "approver.txt"
    }
    
    if dry_run:
        return _handle_dry_run_mode(file_paths, original_cc_count, original_bcc_count)
    else:
        return _handle_live_mode(file_paths, cc_emails, bcc_emails, original_cc_count, original_bcc_count)


def _handle_dry_run_mode(file_paths: Dict[str, Path], original_cc_count: int, original_bcc_count: int) -> Tuple[List[str], List[str], List[str], int, int, int]:
    """Handle recipient processing for dry-run mode."""
    
    # Load approvers for dry-run
    approver_emails = read_recipients(file_paths['approver'])
    final_recipients = deduplicate_emails(approver_emails)
    
    if not final_recipients:
        log_and_print("error", "No valid approver emails found in approver.txt for dry-run mode")
        sys.exit(1)
    
    # No CC/BCC in dry-run mode
    final_cc_recipients = []
    final_bcc_recipients = []
    
    # Calculate original recipient counts for display
    original_recipients_count = _calculate_original_recipients_for_dry_run(file_paths)
    
    # Display dry-run summary
    total_original = original_recipients_count + original_cc_count + original_bcc_count
    log_and_print("draft", f"DRY-RUN MODE: Will send to {len(final_recipients)} approvers instead of {total_original} actual recipients")
    
    return (final_recipients, final_cc_recipients, final_bcc_recipients, 
            original_recipients_count, original_cc_count, original_bcc_count)


def _calculate_original_recipients_for_dry_run(file_paths: Dict[str, Path]) -> int:
    """Calculate what the original recipient count would be for dry-run display."""
    
    original_recipients = []
    
    # Check existing to.txt with disclaimer
    if file_paths['to'].is_file():
        _display_dry_run_disclaimer()
        original_recipients = read_recipients(file_paths['to'])
        log_and_print("info", f"DRY-RUN: Loaded {len(original_recipients)} recipients from existing to.txt")
        
        # Merge with additional_to.txt if present
        if file_paths['additional_to'].is_file():
            original_recipients = _merge_additional_recipients(
                original_recipients, file_paths['additional_to'], "DRY-RUN"
            )
    
    # Generate from filter logic if no to.txt
    elif file_paths['filter'].is_file() and INVENTORY_PATH.is_file():
        original_recipients = _generate_recipients_from_filter(file_paths['filter'])
        log_and_print("info", f"DRY-RUN: Filter logic would generate {len(original_recipients)} recipients")
        
        # Merge with additional_to.txt if present
        if file_paths['additional_to'].is_file():
            original_recipients = _merge_additional_recipients(
                original_recipients, file_paths['additional_to'], "DRY-RUN"
            )
        
        # Create to.txt for future reference
        if original_recipients:
            write_recipients_to_file(file_paths['to'], original_recipients)
            log_and_print("info", f"DRY-RUN: Would create to.txt with {len(original_recipients)} merged recipients")
    
    # Use only additional_to.txt as fallback
    elif file_paths['additional_to'].is_file():
        original_recipients = read_recipients(file_paths['additional_to'])
        log_and_print("info", f"DRY-RUN: Would use {len(original_recipients)} recipients from additional_to.txt only")
        
        if original_recipients:
            write_recipients_to_file(file_paths['to'], original_recipients)
            log_and_print("info", f"DRY-RUN: Would create to.txt from additional_to.txt with {len(original_recipients)} recipients")
    
    return len(deduplicate_emails(original_recipients))


def _handle_live_mode(file_paths: Dict[str, Path], cc_emails: List[str], bcc_emails: List[str], 
                     original_cc_count: int, original_bcc_count: int) -> Tuple[List[str], List[str], List[str], int, int, int]:
    """Handle recipient processing for live mode."""
    
    # Process CC/BCC for live mode
    final_cc_recipients = deduplicate_emails(cc_emails)
    final_bcc_recipients = deduplicate_emails(bcc_emails)
    
    # Get TO recipients using priority system
    recipients = _get_to_recipients_with_priority(file_paths)
    
    # Validate that we have at least some recipients
    if not recipients and not final_cc_recipients and not final_bcc_recipients:
        log_and_print("error", "No valid recipient source found (no TO, CC, or BCC recipients)")
        sys.exit(1)
    elif not recipients:
        log_and_print("info", "No TO recipients found, but CC/BCC recipients available")
    
    final_recipients = deduplicate_emails(recipients)
    original_recipients_count = len(final_recipients)
    
    return (final_recipients, final_cc_recipients, final_bcc_recipients, 
            original_recipients_count, original_cc_count, original_bcc_count)


def _get_to_recipients_with_priority(file_paths: Dict[str, Path]) -> List[str]:
    """Get TO recipients using the established priority system."""
    
    recipients = []
    
    # Priority 1: Use existing to.txt
    if file_paths['to'].is_file():
        recipients = read_recipients(file_paths['to'])
        log_and_print("info", f"Loaded {len(recipients)} recipients from to.txt")
        
        # Merge with additional_to.txt if present
        if file_paths['additional_to'].is_file():
            recipients = _merge_additional_recipients(recipients, file_paths['additional_to'], "LIVE")
    
    # Priority 2: Generate from filter logic
    elif file_paths['filter'].is_file() and INVENTORY_PATH.is_file():
        recipients = _generate_recipients_from_filter(file_paths['filter'])
        log_and_print("info", f"Filter logic generated {len(recipients)} recipients")
        
        # Merge with additional_to.txt if present
        if file_paths['additional_to'].is_file():
            recipients = _merge_additional_recipients(recipients, file_paths['additional_to'], "LIVE")
        
        # Save merged results to to.txt
        if recipients:
            write_recipients_to_file(file_paths['to'], recipients)
            merge_info = "merged recipients (filter + additional)" if file_paths['additional_to'].is_file() else "filter recipients"
            log_and_print("file", f"Created to.txt with {len(recipients)} {merge_info}")
    
    # Priority 3: Use only additional_to.txt
    elif file_paths['additional_to'].is_file():
        recipients = read_recipients(file_paths['additional_to'])
        if recipients:
            log_and_print("info", f"No to.txt or filter.txt found - using {len(recipients)} recipients from additional_to.txt only")
            write_recipients_to_file(file_paths['to'], recipients)
            log_and_print("file", f"Created to.txt from additional_to.txt with {len(recipients)} recipients")
        else:
            log_and_print("warning", "Found additional_to.txt but it contains no valid recipients")
    
    return recipients


def _generate_recipients_from_filter(filter_file_path: Path) -> List[str]:
    """Generate recipients from filter logic."""
    filters = read_file(filter_file_path).splitlines()
    return apply_filter_logic(filters, INVENTORY_PATH)


def _merge_additional_recipients(base_recipients: List[str], additional_file_path: Path, mode_prefix: str) -> List[str]:
    """Merge additional recipients with base recipients and log the results."""
    
    additional_recipients = read_recipients(additional_file_path)
    if not additional_recipients:
        log_and_print("info", f"Found empty additional_to.txt - no recipients to merge")
        return base_recipients
    
    original_count = len(base_recipients)
    merged_recipients = merge_recipients(base_recipients, additional_recipients)
    added_count = len(merged_recipients) - original_count
    
    log_and_print("info", f"Found additional_to.txt with {len(additional_recipients)} recipients")
    
    if added_count > 0:
        log_and_print("info", f"{mode_prefix}: Added {added_count} new recipients from additional_to.txt")
        log_and_print("info", f"Total recipients after merge: {len(merged_recipients)} (was {original_count})")
    else:
        log_and_print("info", f"{mode_prefix}: No new recipients added - all {len(additional_recipients)} from additional_to.txt already exist")
        log_and_print("info", f"Total recipients remain: {len(merged_recipients)}")
    
    return merged_recipients


def _display_dry_run_disclaimer():
    """Display the dry-run disclaimer for existing to.txt files."""
    print()
    print(f"\033[1m\033[91m{'=' * 80}\033[0m")
    print(f"\033[1m\033[91m                            ‚ö†Ô∏è  IMPORTANT DISCLAIMER ‚ö†Ô∏è\033[0m")
    print(f"\033[1m\033[91m{'=' * 80}\033[0m")
    print()
    print(f"\033[1m\033[93m‚ö†Ô∏è  DISCLAIMER: Existing to.txt found - dry-run will NOT overwrite it\033[0m")
    print(f"\033[1m\033[94müí° To see fresh filter results, delete to.txt and run dry-run again\033[0m")
    print(f"\033[1mCurrent to.txt will be preserved for recipient count display\033[0m")
    print()
    print(f"\033[1m\033[91m{'=' * 80}\033[0m")
    print()
    
    log_and_print("info", "‚ö†Ô∏è  DISCLAIMER: Existing to.txt found - dry-run will NOT overwrite it")
    log_and_print("info", "üí° To see fresh filter results, delete to.txt and run dry-run again")
           
            
def extract_field_values_from_matched_rows(filter_line: str, field_names: List[str], inventory_path: Path, base_folder: Path) -> Dict[str, str]:
    """
    Extract field values from CSV rows that match the given filter condition.
    
    Enhanced version with better error handling, performance optimizations, and cleaner code structure.
    
    Args:
        filter_line: Filter condition to match rows against
        field_names: List of field names to extract values for
        inventory_path: Path to global inventory CSV file
        base_folder: Base folder path for checking local inventory and table-columns.txt
    
    Returns:
        Dictionary mapping field names to their extracted/generated values
    """
    
    # Initialize field values dictionary
    field_values = {field: "" for field in field_names}
    
    if not field_names:
        log_and_print("info", "No field names provided - skipping field extraction")
        return field_values
    
    # Get inventory configuration
    inventory_config = _get_inventory_configuration(inventory_path, base_folder)
    if not inventory_config['inventory_path'].exists():
        log_and_print("warning", f"Inventory file not found: {inventory_config['inventory_path']}")
        return field_values
    
    # Get table configuration for dynamic fields
    table_config = _get_table_configuration(base_folder, field_names)
    
    # Process CSV data and extract matched rows
    try:
        matched_rows = _extract_matching_rows(
            inventory_config['inventory_path'], 
            filter_line, 
            inventory_config['source_name']
        )
        
        if not matched_rows:
            log_and_print("warning", f"No rows matched filter: {filter_line}")
            return field_values
        
        # Extract regular field values
        _extract_regular_field_values(field_values, field_names, matched_rows, inventory_config['headers'])
        
        # Generate dynamic table fields if needed
        if table_config['has_table_columns'] and table_config['table_fields']:
            _generate_dynamic_table_fields(field_values, field_names, matched_rows, table_config)
        
        # Log extraction summary
        _log_extraction_summary(field_values, matched_rows, table_config)
        
    except Exception as e:
        log_and_print("error", f"Failed to extract field values: {e}")
        log_and_print("error", f"Filter: {filter_line}")
    
    return field_values


def _get_inventory_configuration(inventory_path: Path, base_folder: Path) -> Dict:
    """Determine which inventory file to use and get its configuration."""
    
    local_inventory = base_folder / "field-inventory.csv"
    
    if local_inventory.exists():
        inventory_path = local_inventory
        source_name = "local field-inventory.csv"
        log_and_print("info", f"Using local field-inventory.csv for field extraction (priority)")
    else:
        source_name = "global inventory.csv"
        log_and_print("info", f"Using global inventory.csv for field extraction (fallback)")
    
    # Get headers if file exists
    headers = []
    if inventory_path.exists():
        try:
            with open(inventory_path, newline='', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                headers = [h.strip() for h in (reader.fieldnames or [])]
        except Exception as e:
            log_and_print("warning", f"Could not read headers from {source_name}: {e}")
    
    return {
        'inventory_path': inventory_path,
        'source_name': source_name,
        'headers': headers
    }


def _get_table_configuration(base_folder: Path, field_names: List[str]) -> Dict:
    """Get table configuration for dynamic field generation."""
    
    table_columns_file = base_folder / "table-columns.txt"
    has_table_columns = table_columns_file.exists()
    table_fields = []
    
    # Handle backward compatibility for dynamic_table
    needs_table_generation = any(
        field in field_names 
        for field in ["table_rows", "styled_table_rows", "simple_table_rows", 
                     "csv_table_rows", "table_headers", "dynamic_table"]
    )
    
    if has_table_columns and needs_table_generation:
        try:
            table_content = table_columns_file.read_text(encoding="utf-8")
            table_fields = [line.strip() for line in table_content.splitlines() if line.strip()]
            
            if table_fields:
                log_and_print("info", f"Using table-columns.txt for dynamic table: {', '.join(table_fields)}")
            else:
                log_and_print("warning", "table-columns.txt is empty - no table columns to use")
        except Exception as e:
            log_and_print("error", f"Error reading table-columns.txt: {e}")
            has_table_columns = False
    
    elif needs_table_generation and not has_table_columns:
        log_and_print("warning", "Table-related fields requested but table-columns.txt not found - skipping table generation")
    
    # Handle dynamic_table backward compatibility
    if "dynamic_table" in field_names and "table_rows" not in field_names:
        if has_table_columns and table_fields:
            field_names.append("table_rows")
            log_and_print("info", "Auto-added table_rows because dynamic_table was requested")
    
    return {
        'has_table_columns': has_table_columns,
        'table_fields': table_fields,
        'table_columns_file': table_columns_file
    }


def _extract_matching_rows(inventory_path: Path, filter_line: str, source_name: str) -> List[Dict]:
    """Extract rows from CSV that match the filter condition."""
    
    matched_rows = []
    
    try:
        with open(inventory_path, newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                # Clean row data by stripping whitespace from keys and values
                cleaned_row = {
                    k.strip(): v.strip() 
                    for k, v in row.items() 
                    if k  # Skip empty keys
                }
                
                if matches_filter_conditions(cleaned_row, [filter_line]):
                    matched_rows.append(cleaned_row)
        
        log_and_print("info", f"Found {len(matched_rows)} matching rows in {source_name}")
        
    except Exception as e:
        log_and_print("error", f"Error reading {source_name}: {e}")
        raise
    
    return matched_rows


def _extract_regular_field_values(field_values: Dict[str, str], field_names: List[str], 
                                matched_rows: List[Dict], headers: List[str]) -> None:
    """Extract values for regular (non-dynamic) fields from matched rows."""
    
    # Define dynamic fields that should be skipped in regular extraction
    DYNAMIC_FIELD_PATTERNS = {
        "table_rows", "styled_table_rows", "simple_table_rows", 
        "csv_table_rows", "table_headers", "dynamic_table"
    }
    
    extracted_fields = []
    
    for field in field_names:
        # Skip dynamic table fields - they're handled separately
        if field in DYNAMIC_FIELD_PATTERNS:
            continue
            
        if field not in headers:
            log_and_print("warning", f"Field '{field}' not found in CSV headers")
            continue
        
        # Collect unique values across all matched rows
        values = set()
        for row in matched_rows:
            value = row.get(field, "").strip()
            if value:
                # Handle comma-separated values within cells
                cell_values = [v.strip() for v in value.split(",") if v.strip()]
                values.update(cell_values)
        
        # Store as comma-separated sorted string
        if values:
            field_values[field] = ",".join(sorted(values))
            extracted_fields.append(field)
    
    if extracted_fields:
        log_and_print("info", f"Extracted values for {len(extracted_fields)} regular fields: {', '.join(extracted_fields)}")


def _generate_dynamic_table_fields(field_values: Dict[str, str], field_names: List[str], 
                                 matched_rows: List[Dict], table_config: Dict) -> None:
    """Generate dynamic table-related fields."""
    
    table_fields = table_config['table_fields']
    table_generators = {
        "table_rows": lambda: _generate_table_rows(matched_rows, table_fields, "default"),
        "styled_table_rows": lambda: _generate_table_rows(matched_rows, table_fields, "striped"),
        "simple_table_rows": lambda: _generate_table_rows(matched_rows, table_fields, "simple"),
        "csv_table_rows": lambda: _generate_csv_table_rows(matched_rows, table_fields),
        "table_headers": lambda: _generate_table_headers(table_fields),
        "dynamic_table": lambda: field_values.get("table_rows", "")  # Backward compatibility
    }
    
    generated_fields = []
    
    for field in field_names:
        if field in table_generators:
            try:
                field_values[field] = table_generators[field]()
                generated_fields.append(field)
            except Exception as e:
                log_and_print("error", f"Failed to generate {field}: {e}")
                field_values[field] = ""
    
    if generated_fields:
        log_and_print("info", f"Generated dynamic table with {len(matched_rows)} rows using {len(table_fields)} columns")
        log_and_print("info", f"Generated fields: {', '.join(generated_fields)}")


def _generate_table_rows(matched_rows: List[Dict], table_fields: List[str], style: str = "default") -> str:
    """Generate HTML table rows with specified styling."""
    
    def escape_html(value: str) -> str:
        """Escape HTML special characters."""
        return str(value).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    
    rows = []
    
    for i, row in enumerate(matched_rows):
        # Determine row styling
        if style == "striped":
            bg_color = "#f9f9f9" if i % 2 == 0 else "#ffffff"
            tr_style = f' style="background-color: {bg_color};"'
        else:
            tr_style = ""
        
        # Build row HTML
        row_html = f"        <tr{tr_style}>\n"
        
        for col in table_fields:
            value = escape_html(row.get(col, ""))
            
            if style == "simple":
                cell_style = ""
            else:
                cell_style = ' style="padding: 10px; border: 1px solid #ddd;"'
            
            row_html += f"            <td{cell_style}>{value}</td>\n"
        
        row_html += "        </tr>"
        rows.append(row_html)
    
    return "\n".join(rows)


def _generate_csv_table_rows(matched_rows: List[Dict], table_fields: List[str]) -> str:
    """Generate pipe-separated table rows for CSV-style display."""
    
    csv_rows = []
    for row in matched_rows:
        row_values = [row.get(col, "") for col in table_fields]
        csv_rows.append(" | ".join(row_values))
    
    return "\n".join(csv_rows)


def _generate_table_headers(table_fields: List[str]) -> str:
    """Generate HTML table headers."""
    
    headers = []
    for col in table_fields:
        # Convert field names to display-friendly format
        display_name = col.replace("_", " ").title()
        header_html = f'            <th style="padding: 10px; border: 1px solid #ddd; background-color: #f5f5f5;">{display_name}</th>'
        headers.append(header_html)
    
    return "\n".join(headers)


def _log_extraction_summary(field_values: Dict[str, str], matched_rows: List[Dict], table_config: Dict) -> None:
    """Log a comprehensive summary of the field extraction results."""
    
    # Count different types of fields
    regular_fields = []
    dynamic_fields = []
    empty_fields = []
    
    DYNAMIC_FIELD_PATTERNS = {
        "table_rows", "styled_table_rows", "simple_table_rows", 
        "csv_table_rows", "table_headers", "dynamic_table"
    }
    
    for field_name, field_value in field_values.items():
        if field_value:
            if field_name in DYNAMIC_FIELD_PATTERNS:
                dynamic_fields.append(field_name)
            else:
                # For regular fields, show value count
                value_count = len(field_value.split(',')) if ',' in field_value else 1
                preview = field_value[:50] + "..." if len(field_value) > 50 else field_value
                regular_fields.append(f"{field_name}=[{preview}]({value_count} values)")
        else:
            empty_fields.append(field_name)
    
    # Log results
    if regular_fields:
        log_and_print("info", f"Regular fields extracted: {', '.join(regular_fields)}")
    
    if dynamic_fields:
        log_and_print("info", f"Dynamic fields generated: {', '.join(dynamic_fields)}")
    
    if empty_fields:
        log_and_print("warning", f"No values found for fields: {', '.join(empty_fields)}")
        log_and_print("info", "Check if these fields exist in the CSV and have data in matched rows")
    
    # Overall summary
    total_fields = len(field_values)
    successful_fields = len(regular_fields) + len(dynamic_fields)
    
    if successful_fields > 0:
        log_and_print("info", f"Field extraction completed: {successful_fields}/{total_fields} fields populated from {len(matched_rows)} matched rows")
    else:
        log_and_print("warning", f"No field values extracted from {len(matched_rows)} matched rows - template placeholders will remain unchanged")           
            
            
            
 def get_recipients_for_multi_mode(base_folder: Path, dry_run: bool = False) -> Tuple[List[Dict], List[str], List[str], int, int, int]:
    """
    Get recipients for multi mode operation with enhanced error handling and validation.
    
    This function processes multiple filter conditions from filter.txt and creates individual
    email configurations for each filter, with optional field substitution and comprehensive
    recipient management including CC/BCC handling.
    
    Args:
        base_folder: Path to the base folder containing configuration files
        dry_run: If True, replaces recipients with approvers for testing
    
    Returns:
        Tuple containing:
        - email_configs: List of email configuration dictionaries
        - final_cc_recipients: List of CC recipients (empty in dry_run)
        - final_bcc_recipients: List of BCC recipients (empty in dry_run)
        - total_original_recipients_count: Total TO recipients across all filters
        - original_cc_count: Original CC recipient count
        - original_bcc_count: Original BCC recipient count
    
    Raises:
        SystemExit: If critical validation fails or no valid configurations are created
    """
    
    # Step 1: Load and validate filter conditions
    filter_file = base_folder / "filter.txt"
    if not filter_file.exists():
        log_and_print("error", "filter.txt not found - required for multi mode")
        sys.exit(1)
    
    try:
        raw_filters = read_file(filter_file).splitlines()
        # Filter out empty lines and comments, preserve line numbers for error reporting
        active_filters = []
        for line_num, line in enumerate(raw_filters, 1):
            stripped = line.strip()
            if stripped and not stripped.startswith('#'):
                active_filters.append({
                    'condition': stripped,
                    'line_number': line_num,
                    'original_line': line
                })
        
        if not active_filters:
            log_and_print("error", "No valid filter conditions found in filter.txt (only comments/empty lines)")
            sys.exit(1)
        
        log_and_print("info", f"Loaded {len(active_filters)} active filter conditions from filter.txt")
        
    except Exception as exc:
        log_and_print("error", f"Failed to read filter.txt: {exc}")
        sys.exit(1)
    
    # Step 2: Load field names for template substitution (optional)
    field_names = []
    field_file = base_folder / "field.txt"
    if field_file.exists():
        try:
            field_content = read_file(field_file)
            field_names = [line.strip() for line in field_content.splitlines() if line.strip()]
            if field_names:
                log_and_print("info", f"Loaded {len(field_names)} field names for template substitution")
                log_and_print("info", f"Fields: {', '.join(field_names)}")
            else:
                log_and_print("info", "field.txt exists but is empty - no template substitution")
        except Exception as exc:
            log_and_print("warning", f"Error reading field.txt: {exc} - continuing without field substitution")
    else:
        log_and_print("info", "No field.txt found - template substitution disabled")
    
    # Step 3: Load CC and BCC recipients and preserve original counts
    cc_emails = read_recipients(base_folder / "cc.txt")
    bcc_emails = read_recipients(base_folder / "bcc.txt")
    
    # Store original counts immediately before any modifications
    original_cc_count = len(deduplicate_emails(cc_emails))
    original_bcc_count = len(deduplicate_emails(bcc_emails))
    
    if cc_emails:
        log_and_print("info", f"Loaded {len(cc_emails)} CC recipients (will be included in each email)")
    if bcc_emails:
        log_and_print("info", f"Loaded {len(bcc_emails)} BCC recipients (will be included in each email)")
    
    # Step 4: Load additional recipients (applied to all filters)
    additional_recipients = []
    additional_to_file = base_folder / "additional_to.txt"
    if additional_to_file.exists():
        try:
            additional_recipients = read_recipients(additional_to_file)
            if additional_recipients:
                log_and_print("info", f"Loaded {len(additional_recipients)} additional recipients (will be added to each filter)")
            else:
                log_and_print("info", "additional_to.txt exists but contains no valid recipients")
        except Exception as exc:
            log_and_print("warning", f"Error reading additional_to.txt: {exc} - continuing without additional recipients")
    
    # Step 5: Process each filter to create email configurations
    email_configs = []
    total_original_recipients_count = 0
    failed_filters = []
    
    for filter_info in active_filters:
        filter_condition = filter_info['condition']
        filter_line_num = filter_info['line_number']
        
        log_and_print("processing", f"Processing filter {len(email_configs) + 1}/{len(active_filters)} (line {filter_line_num}): {filter_condition}")
        
        try:
            # Apply filter logic to get base recipients
            base_recipients = apply_filter_logic([filter_condition], INVENTORY_PATH)
            base_recipients = deduplicate_emails(base_recipients)
            
            if not base_recipients:
                log_and_print("warning", f"Filter line {filter_line_num} matched no recipients: {filter_condition}")
                failed_filters.append({
                    'line_number': filter_line_num,
                    'condition': filter_condition,
                    'reason': 'No matching recipients'
                })
                continue
            
            # Merge with additional recipients if available
            final_filter_recipients = base_recipients.copy()
            if additional_recipients:
                original_count = len(final_filter_recipients)
                final_filter_recipients = merge_recipients(final_filter_recipients, additional_recipients)
                added_count = len(final_filter_recipients) - original_count
                
                if added_count > 0:
                    log_and_print("info", f"Filter {len(email_configs) + 1}: Added {added_count} additional recipients")
                else:
                    log_and_print("info", f"Filter {len(email_configs) + 1}: All {len(additional_recipients)} additional recipients already matched by filter")
            
            # Store the original recipient count before any dry-run modifications
            original_recipients_count = len(final_filter_recipients)
            
            # Extract field values for template substitution
            field_values = {}
            if field_names:
                log_and_print("info", f"Filter {len(email_configs) + 1}: Extracting field values for template substitution...")
                
                try:
                    field_values = extract_field_values_from_matched_rows(
                        filter_condition, field_names, INVENTORY_PATH, base_folder
                    )
                    
                    # Validate and report field extraction results
                    successful_extractions = []
                    empty_fields = []
                    
                    for field_name in field_names:
                        field_value = field_values.get(field_name, "")
                        if field_value:
                            # Count unique values for reporting
                            value_count = len(set(field_value.split(','))) if ',' in field_value else 1
                            # Create display-friendly preview
                            if len(field_value) <= 100:
                                display_value = field_value
                            else:
                                display_value = f"{field_value[:97]}..."
                            
                            successful_extractions.append(f"{field_name}=[{display_value}] ({value_count} values)")
                        else:
                            empty_fields.append(field_name)
                    
                    if successful_extractions:
                        log_and_print("info", f"Filter {len(email_configs) + 1} extracted: {'; '.join(successful_extractions)}")
                    
                    if empty_fields:
                        log_and_print("warning", f"Filter {len(email_configs) + 1} no data for fields: {', '.join(empty_fields)}")
                        log_and_print("info", "Empty fields may indicate missing data in matched inventory rows")
                    
                    # Warn if no substitutions will occur
                    if field_names and not any(field_values.values()):
                        log_and_print("warning", f"Filter {len(email_configs) + 1}: No field values extracted - template placeholders will remain unchanged")
                
                except Exception as exc:
                    log_and_print("error", f"Filter {len(email_configs) + 1}: Field value extraction failed: {exc}")
                    # Continue without field values rather than failing completely
                    field_values = {field: "" for field in field_names}
            
            # Create email configuration
            email_config = {
                'filter_line': filter_condition,
                'filter_line_number': filter_line_num,
                'recipients': final_filter_recipients.copy(),  # Current recipients (modified for dry-run)
                'original_recipients': final_filter_recipients.copy(),  # Preserved original recipients
                'field_values': field_values,
                'filter_number': len(email_configs) + 1,
                'original_recipients_count': original_recipients_count,
                'base_recipients_count': len(base_recipients),
                'additional_recipients_added': len(final_filter_recipients) - len(base_recipients)
            }
            
            email_configs.append(email_config)
            total_original_recipients_count += original_recipients_count
            
            log_and_print("success", f"Filter {len(email_configs)} configured: {original_recipients_count} recipients")
            
        except Exception as exc:
            log_and_print("error", f"Filter line {filter_line_num} processing failed: {exc}")
            failed_filters.append({
                'line_number': filter_line_num,
                'condition': filter_condition,
                'reason': f'Processing error: {exc}'
            })
            continue
    
    # Step 6: Validate that we have at least one successful configuration
    if not email_configs:
        log_and_print("error", "No filters generated valid recipient configurations")
        if failed_filters:
            log_and_print("error", "Failed filters summary:")
            for failed in failed_filters:
                log_and_print("error", f"  Line {failed['line_number']}: {failed['condition']} - {failed['reason']}")
        sys.exit(1)
    
    # Step 7: Report summary of successful configurations
    log_and_print("info", f"Multi mode configuration complete:")
    log_and_print("info", f"  - Successful filters: {len(email_configs)}/{len(active_filters)}")
    log_and_print("info", f"  - Total unique TO recipients: {total_original_recipients_count}")
    log_and_print("info", f"  - Individual emails to generate: {len(email_configs)}")
    
    if failed_filters:
        log_and_print("warning", f"Failed filters: {len(failed_filters)}")
        for failed in failed_filters[:3]:  # Show first 3 failures
            log_and_print("warning", f"  Line {failed['line_number']}: {failed['reason']}")
        if len(failed_filters) > 3:
            log_and_print("warning", f"  ... and {len(failed_filters) - 3} more failures")
    
    # Step 8: Handle dry-run mode
    if dry_run:
        # Load approvers for dry-run mode
        approver_emails = read_recipients(base_folder / "approver.txt")
        approver_emails = deduplicate_emails(approver_emails)
        
        if not approver_emails:
            log_and_print("error", "DRY-RUN mode requires valid approver emails in approver.txt")
            sys.exit(1)
        
        # Replace recipients with approvers while preserving original data
        for config in email_configs:
            config['recipients'] = approver_emails.copy()
        
        # Clear CC/BCC for dry-run
        final_cc_recipients = []
        final_bcc_recipients = []
        
        # Save original recipient data using preserved original_recipients
        try:
            original_configs_for_saving = []
            for config in email_configs:
                save_config = config.copy()
                save_config['recipients'] = config['original_recipients']  # Use original recipients for saving
                original_configs_for_saving.append(save_config)
            
            save_multi_mode_recipients(base_folder, original_configs_for_saving, cc_emails, bcc_emails)
            
        except Exception as exc:
            log_and_print("warning", f"Failed to save original recipient data: {exc}")
        
        log_and_print("draft", f"DRY-RUN MODE configured:")
        log_and_print("draft", f"  - Will send {len(email_configs)} draft emails to {len(approver_emails)} approver(s)")
        log_and_print("draft", f"  - Original campaign would target {total_original_recipients_count} TO recipients")
        log_and_print("draft", f"  - Original CC/BCC: {original_cc_count}/{original_bcc_count} per email")
        
    else:
        # Live mode - use actual CC/BCC recipients
        final_cc_recipients = deduplicate_emails(cc_emails)
        final_bcc_recipients = deduplicate_emails(bcc_emails)
        
        # Save recipients for live mode
        try:
            save_multi_mode_recipients(base_folder, email_configs, final_cc_recipients, final_bcc_recipients)
        except Exception as exc:
            log_and_print("warning", f"Failed to save recipient data: {exc}")
        
        log_and_print("info", f"LIVE MODE configured:")
        log_and_print("info", f"  - Will send {len(email_configs)} individual emails")
        log_and_print("info", f"  - Total TO recipients: {total_original_recipients_count}")
        log_and_print("info", f"  - CC/BCC per email: {len(final_cc_recipients)}/{len(final_bcc_recipients)}")
    
    return (
        email_configs,
        final_cc_recipients,
        final_bcc_recipients,
        total_original_recipients_count,
        original_cc_count,
        original_bcc_count
    )           
            
            
            
            
   



def save_multi_mode_recipients(base_folder: Path, email_configs: List[Dict], 
                               cc_recipients: List[str] = None, bcc_recipients: List[str] = None) -> None:
    """
    """
    cc_recipients = cc_recipients or []
    bcc_recipients = bcc_recipients or []
    
    try:
        # Create a recipients subfolder for better organization
        recipients_folder = base_folder / "recipients"
        recipients_folder.mkdir(exist_ok=True)
        
        # Save individual filter recipient files
        all_unique_recipients = set()
        filter_summaries = []
        
        for i, config in enumerate(email_configs, 1):
            filter_line = config['filter_line']
            recipients = config['recipients']
            field_values = config.get('field_values', {})
            
            # Create a safe filename from filter line
            safe_filter_name = re.sub(r'[^\w\s.-]', '_', filter_line)[:50]  # Limit length
            safe_filter_name = re.sub(r'\s+', '_', safe_filter_name)  # Replace spaces with underscores
            
            # Save individual filter recipients
            filter_file = recipients_folder / f"filter_{i:03d}_{safe_filter_name}.txt"
            
            try:
                with filter_file.open('w', encoding='utf-8') as f:
                    # Write header with filter info
                    f.write(f"# Filter {i}: {filter_line}\n")
                    f.write(f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"# Recipients: {len(recipients)}\n")
                    if field_values:
                        f.write(f"# Field values: {field_values}\n")
                    f.write("#\n")
                    
                    # Write recipients
                    for email in recipients:
                        f.write(f"{email}\n")
                        all_unique_recipients.add(email.lower())
                
                log_and_print("file", f"Saved {len(recipients)} recipients for filter {i} to {filter_file.name}")
                
                # Add to summary
                filter_summaries.append({
                    'filter_number': i,
                    'filter_line': filter_line,
                    'filename': filter_file.name,
                    'recipient_count': len(recipients),
                    'field_values': field_values
                })
                
            except Exception as exc:
                log_and_print("error", f"Failed to save recipients for filter {i}: {exc}")
        
        # Save CC recipients if any
        if cc_recipients:
            cc_file = recipients_folder / "cc_recipients.txt"
            try:
                with cc_file.open('w', encoding='utf-8') as f:
                    f.write(f"# CC Recipients\n")
                    f.write(f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"# Recipients: {len(cc_recipients)}\n")
                    f.write("#\n")
                    for email in cc_recipients:
                        f.write(f"{email}\n")
                log_and_print("file", f"Saved {len(cc_recipients)} CC recipients to {cc_file.name}")
            except Exception as exc:
                log_and_print("error", f"Failed to save CC recipients: {exc}")
        
        # Save BCC recipients if any
        if bcc_recipients:
            bcc_file = recipients_folder / "bcc_recipients.txt"
            try:
                with bcc_file.open('w', encoding='utf-8') as f:
                    f.write(f"# BCC Recipients\n")
                    f.write(f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"# Recipients: {len(bcc_recipients)}\n")
                    f.write("#\n")
                    for email in bcc_recipients:
                        f.write(f"{email}\n")
                log_and_print("file", f"Saved {len(bcc_recipients)} BCC recipients to {bcc_file.name}")
            except Exception as exc:
                log_and_print("error", f"Failed to save BCC recipients: {exc}")
        
        # Save comprehensive summary file
        summary_file = recipients_folder / "multi_mode_summary.txt"
        try:
            with summary_file.open('w', encoding='utf-8') as f:
                f.write("MULTI-MODE RECIPIENT SUMMARY\n")
                f.write("=" * 50 + "\n")
                f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Total Filters: {len(email_configs)}\n")
                f.write(f"Unique Recipients (TO): {len(all_unique_recipients)}\n")
                f.write(f"CC Recipients: {len(cc_recipients)}\n")
                f.write(f"BCC Recipients: {len(bcc_recipients)}\n")
                f.write("\n")
                
                # Individual filter details
                f.write("FILTER BREAKDOWN:\n")
                f.write("-" * 30 + "\n")
                total_to_recipients = 0
                
                for summary in filter_summaries:
                    f.write(f"\nFilter {summary['filter_number']}:\n")
                    f.write(f"  Condition: {summary['filter_line']}\n")
                    f.write(f"  Recipients: {summary['recipient_count']}\n")
                    f.write(f"  File: {summary['filename']}\n")
                    if summary['field_values']:
                        f.write(f"  Field Values: {summary['field_values']}\n")
                    total_to_recipients += summary['recipient_count']
                
                f.write(f"\nTOTAL STATISTICS:\n")
                f.write("-" * 20 + "\n")
                f.write(f"Total TO emails across all filters: {total_to_recipients}\n")
                f.write(f"Unique TO recipients: {len(all_unique_recipients)}\n")
                
                if len(email_configs) > 1 and (cc_recipients or bcc_recipients):
                    cc_bcc_total = (len(cc_recipients) + len(bcc_recipients)) * len(email_configs)
                    f.write(f"Total CC/BCC emails (sent with each filter): {cc_bcc_total}\n")
                    f.write(f"  - CC emails: {len(cc_recipients)} √ó {len(email_configs)} = {len(cc_recipients) * len(email_configs)}\n")
                    f.write(f"  - BCC emails: {len(bcc_recipients)} √ó {len(email_configs)} = {len(bcc_recipients) * len(email_configs)}\n")
                
                grand_total = total_to_recipients + (len(cc_recipients) + len(bcc_recipients)) * len(email_configs)
                f.write(f"GRAND TOTAL EMAILS: {grand_total}\n")
                
                # File listing
                f.write(f"\nGENERATED FILES:\n")
                f.write("-" * 20 + "\n")
                for summary in filter_summaries:
                    f.write(f"  {summary['filename']}\n")
                if cc_recipients:
                    f.write(f"  cc_recipients.txt\n")
                if bcc_recipients:
                    f.write(f"  bcc_recipients.txt\n")
                f.write(f"  multi_mode_summary.txt (this file)\n")
            
            log_and_print("file", f"Saved multi-mode summary to {summary_file.name}")
            
        except Exception as exc:
            log_and_print("error", f"Failed to save multi-mode summary: {exc}")
        
        # Save consolidated recipient list (all unique TO recipients)
        if all_unique_recipients:
            all_recipients_file = recipients_folder / "all_unique_recipients.txt"
            try:
                with all_recipients_file.open('w', encoding='utf-8') as f:
                    f.write(f"# All Unique TO Recipients (Multi-Mode)\n")
                    f.write(f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"# Total Unique Recipients: {len(all_unique_recipients)}\n")
                    f.write(f"# Source: {len(email_configs)} filter conditions\n")
                    f.write("#\n")
                    for email in sorted(all_unique_recipients):
                        f.write(f"{email}\n")
                
                log_and_print("file", f"Saved {len(all_unique_recipients)} unique recipients to {all_recipients_file.name}")
                
            except Exception as exc:
                log_and_print("error", f"Failed to save consolidated recipient list: {exc}")
        
        # Log summary of what was saved
        log_and_print("backup", f"Multi-mode recipients saved to {recipients_folder.name}/")
        log_and_print("info", f"Created {len(filter_summaries)} filter files, 1 summary file, 1 consolidated file")
        if cc_recipients or bcc_recipients:
            extra_files = []
            if cc_recipients:
                extra_files.append("CC")
            if bcc_recipients:
                extra_files.append("BCC")
            log_and_print("info", f"Additional files: {', '.join(extra_files)} recipient lists")
        
    except Exception as exc:
        log_and_print("error", f"Error saving multi-mode recipients: {exc}")



def prompt_for_confirmation() -> bool:
    """Prompt the user for a yes/no confirmation to proceed."""
    response = input("Do you want to proceed with sending emails? (yes/no): ").strip().lower()
    return response == 'yes'

def send_via_sendmail(recipients: List[str], subject: str, body_html: str, 
                     from_address: str, attachment_folder: Path = None, 
                     dry_run: bool = False, original_recipients_count: int = 0,
                     base_folder: Path = None, cc_recipients: List[str] = None,
                     bcc_recipients: List[str] = None,
                     original_cc_count: int = 0, original_bcc_count: int = 0,
                     filter_info: str = None) -> bool:
    """Send email using sendmail command. In dry-run mode, sends only to approvers with DRAFT prefix."""
    
    cc_recipients = cc_recipients or []
    bcc_recipients = bcc_recipients or []
    
    # Prepare subject for dry-run mode
    final_subject = subject
    if dry_run:
        # Add DRAFT prefix if not already present
        if not subject.upper().startswith('DRAFT'):
            final_subject = f"DRAFT - {subject}"
        
        # Add recipient count info to body for dry-run
        filter_info_html = f"<p style=\"color: #333333; margin: 4px 0; font-size: 14px;\"><strong>Filter:</strong> {filter_info}</p>" if filter_info else ""
        
        draft_info = f"""
        <div style="background-color: #f8f9fa; border: 2px solid #007BFF; padding: 12px; margin: 10px 0; border-radius: 6px; max-width: 500px; width: 100%; margin-left: 20px;">
            <h3 style="color: #0056b3; margin: 0 0 8px 0; font-size: 16px;">üìù Draft Email ‚Äì Internal Review üîç</h3>
            <p style="color: #333333; margin: 4px 0; font-size: 14px;"><strong>Status:</strong> This is a draft email shared for review and approval.</p>
            {filter_info_html}
            <p style="color: #333333; margin: 4px 0; font-size: 14px;"><strong>Original Recipient Count:</strong> {original_recipients_count}</p>
            <p style="color: #333333; margin: 5px 0;"><strong>Original CC Recipients:</strong> {original_cc_count}</p>
            <p style="color: #333333; margin: 5px 0;"><strong>Original BCC Recipients:</strong> {original_bcc_count}</p>
            <p style="color: #333333; margin: 5px 0;"><strong>Once approved, this message will be delivered to all {original_recipients_count + original_cc_count + original_bcc_count} intended recipients.</strong></p>
        </div>
        <hr style="margin: 16px 0; border: 0; border-top: 1px solid #ddd;">
        """
        body_html = draft_info + body_html
        
        total_original = original_recipients_count + original_cc_count + original_bcc_count
        log_and_print("draft", f"DRAFT mode: Sending to {len(recipients)} approver(s) instead of {total_original} original recipients")
        log_and_print("draft", f"Original breakdown - TO: {original_recipients_count}, CC: {original_cc_count}, BCC: {original_bcc_count}")
        log_and_print("draft", f"Subject: {final_subject}")
        log_and_print("draft", f"Approvers: {', '.join(recipients[:3])}{'...' if len(recipients) > 3 else ''}")
        
        if attachment_folder and attachment_folder.exists():
            attachments = [f.name for f in attachment_folder.iterdir() if f.is_file()]
            if attachments:
                log_and_print("draft", f"Attachments: {', '.join(attachments[:3])}{'...' if len(attachments) > 3 else ''}")
    else:
        total_recipients = len(recipients) + len(cc_recipients) + len(bcc_recipients)
        log_and_print("info", f"LIVE mode: Sending to {total_recipients} total recipients")
        log_and_print("info", f"TO: {len(recipients)}, CC: {len(cc_recipients)}, BCC: {len(bcc_recipients)}")
        log_and_print("info", f"Subject: {final_subject}")
        log_and_print("info", f"TO: {', '.join(recipients[:3])}{'...' if len(recipients) > 3 else ''}")
        if cc_recipients:
            log_and_print("info", f"CC: {', '.join(cc_recipients[:3])}{'...' if len(cc_recipients) > 3 else ''}")
        if bcc_recipients:
            log_and_print("info", f"BCC: {', '.join(bcc_recipients[:3])}{'...' if len(bcc_recipients) > 3 else ''}")
            
        if attachment_folder and attachment_folder.exists():
            attachments = [f.name for f in attachment_folder.iterdir() if f.is_file()]
            if attachments:
                log_and_print("info", f"Attachments: {', '.join(attachments[:3])}{'...' if len(attachments) > 3 else ''}")
    
    try:
        # Create the email message with base_folder for image embedding
        msg = create_email_message(recipients, final_subject, body_html, from_address, 
                                 attachment_folder, base_folder, cc_recipients, bcc_recipients)
        
        # Convert message to string
        email_content = msg.as_string()
        
        # Find sendmail path
        sendmail_path = find_sendmail_path()
        
        # All recipients (TO, CC, BCC) must be provided to sendmail for delivery
        all_recipients_for_delivery = recipients + cc_recipients + bcc_recipients
        
        # Call sendmail with proper arguments
        sendmail_cmd = [sendmail_path, '-f', from_address] + all_recipients_for_delivery
        
        process = subprocess.Popen(
            sendmail_cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        stdout, stderr = process.communicate(input=email_content, timeout=60)
        
        if process.returncode == 0:
            if dry_run:
                log_and_print("success", f"DRAFT email sent successfully to {len(recipients)} approver(s)")
            else:
                log_and_print("success", f"Email sent successfully to {len(all_recipients_for_delivery)} total recipients")
            return True
        else:
            log_and_print("error", f"Sendmail failed with return code {process.returncode}")
            if stderr:
                log_and_print("error", f"Sendmail stderr: {stderr}")
            return False
            
    except FileNotFoundError:
        log_and_print("error", f"Sendmail not found at {sendmail_path}. Please install sendmail.")
        return False
    except subprocess.TimeoutExpired:
        log_and_print("error", "Sendmail timeout - operation took too long")
        return False
    except Exception as exc:
        log_and_print("error", f"Error sending email via sendmail: {exc}")
        return False

def send_single_mode_emails(recipients: List[str], subject: str, body_html: str, 
                           from_address: str, batch_size: int, dry_run: bool = False, 
                           delay: float = 5.0, attachment_folder: Path = None,
                           cc_recipients: List[str] = None, bcc_recipients: List[str] = None,
                           original_recipients_count: int = 0, base_folder: Path = None,
                           original_cc_count: int = 0, original_bcc_count: int = 0) -> None:
    """Send emails in single mode with batching."""
    
    cc_recipients = cc_recipients or []
    bcc_recipients = bcc_recipients or []
    
    # Initialize counters and totals
    total_recipients = len(recipients)
    total_batches = (total_recipients + batch_size - 1) // batch_size if total_recipients > 0 else 0
    successful_batches = 0
    failed_batches = 0
    
    # Handle edge case where no TO recipients but CC/BCC exist
    if total_recipients == 0 and (cc_recipients or bcc_recipients):
        # Create a single "batch" with just CC/BCC recipients
        log_and_print("info", "No TO recipients, sending single email with CC/BCC only")
        
        if dry_run:
            log_and_print("processing", f"Processing DRAFT email (CC/BCC only to approvers)")
        else:
            batch_total = len(cc_recipients) + len(bcc_recipients)
            log_and_print("processing", f"Processing email with {batch_total} CC/BCC recipients only")
        
        # Send email with empty TO list but include CC/BCC
        if send_via_sendmail([], subject, body_html, from_address, attachment_folder, 
                           dry_run, original_recipients_count, base_folder, 
                           cc_recipients, bcc_recipients, original_cc_count, original_bcc_count):
            successful_batches = 1
            log_and_print("success", "CC/BCC-only email completed successfully")
        else:
            failed_batches = 1
            log_and_print("error", "CC/BCC-only email failed")
    else:
        # Process TO recipients in batches
        for i in range(0, total_recipients, batch_size):
            batch = recipients[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            # Include CC/BCC in ALL batches
            current_cc = cc_recipients
            current_bcc = bcc_recipients
            
            if dry_run:
                log_and_print("processing", f"Processing DRAFT batch {batch_num}/{total_batches} ({len(batch)} approver(s))")
            else:
                batch_total = len(batch) + len(current_cc) + len(current_bcc)
                log_and_print("processing", f"Processing batch {batch_num}/{total_batches} ({batch_total} recipients)")
                if current_cc or current_bcc:
                    log_and_print("info", f"CC/BCC included in this batch")
            
            # Send current batch with CC/BCC included
            if send_via_sendmail(batch, subject, body_html, from_address, attachment_folder, 
                               dry_run, original_recipients_count, base_folder, 
                               current_cc, current_bcc, original_cc_count, original_bcc_count):
                successful_batches += 1
                log_and_print("success", f"Batch {batch_num} completed successfully")
            else:
                failed_batches += 1
                log_and_print("error", f"Batch {batch_num} failed")
            
            # Add delay between batches (except for the last batch)
            if i + batch_size < total_recipients and not dry_run:
                log_and_print("info", f"Waiting {delay} seconds before next batch...")
                time.sleep(delay)
    
    # Summary
    if dry_run:
        total_original = original_recipients_count + original_cc_count + original_bcc_count
        log_and_print("info", f"SINGLE MODE DRAFT processing complete: {successful_batches} successful, {failed_batches} failed")
        if total_original > 0:
            log_and_print("info", f"DRAFT emails sent to approvers for campaign targeting {total_original} recipients")
    else:
        log_and_print("info", f"SINGLE MODE batch processing complete: {successful_batches} successful, {failed_batches} failed")
        if successful_batches > 0:
            total_sent = (original_recipients_count + 
                         (original_cc_count * successful_batches) + 
                         (original_bcc_count * successful_batches))
            log_and_print("info", f"Total emails delivered: {total_sent}")
            if successful_batches > 1 and (original_cc_count > 0 or original_bcc_count > 0):
                log_and_print("info", f"Note: CC/BCC recipients received {successful_batches} copies (one per batch)")

def send_multi_mode_emails(email_configs: List[Dict], subject_template: str, body_template: str,
                          from_address: str, dry_run: bool = False, delay: float = 5.0,
                          attachment_folder: Path = None, base_folder: Path = None,
                          cc_recipients: List[str] = None, bcc_recipients: List[str] = None,
                          original_cc_count: int = 0, original_bcc_count: int = 0,
                          batch_size: int = 500) -> None:
    """Send emails in multi mode - one personalized email per filter condition with batching support."""
    
    cc_recipients = cc_recipients or []
    bcc_recipients = bcc_recipients or []
    
    successful_emails = 0
    failed_emails = 0
    total_batches = 0
    successful_batches = 0
    failed_batches = 0
    
    # Track which configs were successful for final calculation
    successful_configs = []
    
    log_and_print("info", f"MULTI MODE: Processing {len(email_configs)} filter conditions with batch-size {batch_size}")
    
    for config_num, config in enumerate(email_configs, 1):
        filter_line = config['filter_line']
        recipients = config['recipients']
        field_values = config.get('field_values', {})
        original_count = config.get('original_recipients_count', len(recipients))
        
        # Personalize subject and body
        personalized_subject = subject_template
        personalized_body = body_template
        
        if field_values:
            personalized_subject = substitute_placeholders(subject_template, field_values)
            personalized_body = substitute_placeholders(body_template, field_values)
            log_and_print("info", f"Filter {config_num}: Personalized subject: {personalized_subject}")
        
        # Calculate batches for this filter
        total_recipients = len(recipients)
        filter_batches = (total_recipients + batch_size - 1) // batch_size if total_recipients > 0 else 0
        total_batches += filter_batches
        
        log_and_print("processing", f"Processing filter {config_num}/{len(email_configs)}: {filter_line}")
        log_and_print("info", f"Recipients: {total_recipients}, Batches: {filter_batches}")
        
        # Handle case where no TO recipients but CC/BCC exist
        if total_recipients == 0 and (cc_recipients or bcc_recipients):
            log_and_print("info", f"Filter {config_num}: No TO recipients, sending single email with CC/BCC only")
            
            filter_info = filter_line if dry_run else None
            if send_via_sendmail([], personalized_subject, personalized_body, from_address,
                               attachment_folder, dry_run, original_count, base_folder,
                               cc_recipients, bcc_recipients, original_cc_count, original_bcc_count,
                               filter_info):
                successful_emails += 1
                successful_batches += 1
                successful_configs.append(config)  # Track successful config
                log_and_print("success", f"Filter {config_num} CC/BCC-only email sent successfully")
            else:
                failed_emails += 1
                failed_batches += 1
                log_and_print("error", f"Filter {config_num} CC/BCC-only email failed")
        else:
            # Process recipients in batches for this filter
            filter_successful_batches = 0
            filter_failed_batches = 0
            
            for i in range(0, total_recipients, batch_size):
                batch = recipients[i:i + batch_size]
                batch_num = i // batch_size + 1
                
                # Include CC/BCC in ALL batches for this filter
                current_cc = cc_recipients
                current_bcc = bcc_recipients
                
                if dry_run:
                    log_and_print("processing", f"Filter {config_num}, Batch {batch_num}/{filter_batches}: DRAFT to {len(batch)} approver(s)")
                else:
                    batch_total = len(batch) + len(current_cc) + len(current_bcc)
                    log_and_print("processing", f"Filter {config_num}, Batch {batch_num}/{filter_batches}: {batch_total} recipients")
                    if current_cc or current_bcc:
                        log_and_print("info", f"CC/BCC included in this batch")
                
                # Send current batch with CC/BCC included
                filter_info = filter_line if dry_run else None
                if send_via_sendmail(batch, personalized_subject, personalized_body, from_address,
                                   attachment_folder, dry_run, original_count, base_folder,
                                   current_cc, current_bcc, original_cc_count, original_bcc_count,
                                   filter_info):
                    filter_successful_batches += 1
                    successful_batches += 1
                    log_and_print("success", f"Filter {config_num}, Batch {batch_num} completed successfully")
                else:
                    filter_failed_batches += 1
                    failed_batches += 1
                    log_and_print("error", f"Filter {config_num}, Batch {batch_num} failed")
                
                # Add delay between batches within the same filter (except for the last batch)
                if i + batch_size < total_recipients and not dry_run:
                    log_and_print("info", f"Waiting {delay} seconds before next batch...")
                    time.sleep(delay)
            
            # Determine if this filter was successful (at least one batch succeeded)
            if filter_successful_batches > 0:
                successful_emails += 1
                successful_configs.append(config)  # Track successful config
                log_and_print("success", f"Filter {config_num} completed: {filter_successful_batches}/{filter_successful_batches + filter_failed_batches} batches successful")
            else:
                failed_emails += 1
                log_and_print("error", f"Filter {config_num} failed: all {filter_failed_batches} batches failed")
        
        # Add delay between filters (except for the last one)
        if config_num < len(email_configs) and not dry_run:
            log_and_print("info", f"Waiting {delay} seconds before next filter...")
            time.sleep(delay)
    
    # Summary
    if dry_run:
        log_and_print("info", f"MULTI MODE DRAFT processing complete:")
        log_and_print("info", f"  - Filters processed: {successful_emails} successful, {failed_emails} failed")
        log_and_print("info", f"  - Batches processed: {successful_batches} successful, {failed_batches} failed")
        log_and_print("info", f"DRAFT emails sent to approvers for {len(email_configs)} individual campaigns")
    else:
        log_and_print("info", f"MULTI MODE processing complete:")
        log_and_print("info", f"  - Filters processed: {successful_emails} successful, {failed_emails} failed")
        log_and_print("info", f"  - Batches processed: {successful_batches} successful, {failed_batches} failed")
        
        if successful_batches > 0:
            # Calculate total emails delivered across all successful batches
            total_emails_delivered = 0
            for config in successful_configs:  # Use successful_configs instead
                recipients_count = len(config['recipients'])
                filter_batches = (recipients_count + batch_size - 1) // batch_size if recipients_count > 0 else 1
                # Each batch includes CC/BCC
                total_emails_delivered += recipients_count + (original_cc_count + original_bcc_count) * filter_batches
            
            log_and_print("info", f"Total individual emails delivered: {total_emails_delivered}")
            if (original_cc_count > 0 or original_bcc_count > 0):
                log_and_print("info", f"Note: CC/BCC recipients received multiple emails (one per batch per filter)")



def embed_images_in_html(html_content: str, base_folder: Path) -> Tuple[str, List[MIMEImage]]:
    """
    Replace image src attributes with cid references and return embedded images.
    """
    images_folder = base_folder / "images"
    embedded_images = []
    
    if not images_folder.exists():
        log_and_print("info", "No images folder found, skipping image embedding")
        return html_content, embedded_images
    
    # Find all img tags with src attributes
    img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
    
    def replace_img_src(match):
        img_tag = match.group(0)
        src = match.group(1)
        
        # Skip if already a cid: reference
        if src.startswith('cid:'):
            return img_tag
            
        # Skip external URLs (keep them as-is, but warn user)
        if src.startswith(('http://', 'https://')):
            log_and_print("warning", f"External image URL found: {src} - may be blocked by email clients")
            return img_tag
        
        # Handle local file references
        image_filename = Path(src).name
        image_path = images_folder / image_filename
        
        if not image_path.exists():
            log_and_print("warning", f"Image file not found: {image_path}")
            return img_tag
        
        try:
            # Read and encode image
            with open(image_path, 'rb') as img_file:
                img_data = img_file.read()
            
            # Create Content-ID
            cid = f"image_{len(embedded_images)}_{image_filename.replace('.', '_')}"
            
            # Create MIME image
            mime_type, _ = mimetypes.guess_type(str(image_path))
            if mime_type and mime_type.startswith('image/'):
                maintype, subtype = mime_type.split('/', 1)
                mime_img = MIMEImage(img_data, subtype)
                mime_img.add_header('Content-ID', f'<{cid}>')
                mime_img.add_header('Content-Disposition', 'inline', filename=image_filename)
                embedded_images.append(mime_img)
                
                # Replace src with cid reference
                new_img_tag = re.sub(r'src=["\'][^"\']+["\']', f'src="cid:{cid}"', img_tag)
                log_and_print("info", f"Embedded image: {image_filename} as {cid}")
                return new_img_tag
            else:
                log_and_print("warning", f"Unsupported image type: {image_path}")
                return img_tag
                
        except Exception as exc:
            log_and_print("error", f"Failed to embed image {image_path}: {exc}")
            return img_tag
    
    # Replace all img tags
    modified_html = re.sub(img_pattern, replace_img_src, html_content)
    
    if embedded_images:
        log_and_print("info", f"Embedded {len(embedded_images)} image(s) in email")
    
    return modified_html, embedded_images

def get_inventory_fields_for_help() -> str:
    """
    Get available fields from inventory.csv for CLI help display.
    Returns a formatted string of available fields or error message.
    """
    try:
        if not INVENTORY_PATH.exists():
            return "  [Inventory file not found at /notifybot/inventory/inventory.csv]"
        
        with open(INVENTORY_PATH, mode="r", newline="", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            available_fields = reader.fieldnames or []
            
        if not available_fields:
            return "  [No headers found in inventory.csv]"
        
        # Format fields in a nice column layout
        field_list = sorted(available_fields)
        formatted_fields = []
        
        # Group fields in rows of 4 for better readability
        for i in range(0, len(field_list), 4):
            row_fields = field_list[i:i+4]
            formatted_row = "  " + " | ".join(f"{field:<15}" for field in row_fields)
            formatted_fields.append(formatted_row)
        
        result = f"  Available fields in inventory.csv ({len(field_list)} total):\n"
        result += "\n".join(formatted_fields)
        return result
        
    except Exception as exc:
        return f"  [Error reading inventory.csv: {exc}]"


def main():
    """Enhanced main function with improved organization and error handling"""
    
    # Initialize logging first
    setup_logging()
    
    try:
        # Parse arguments with better help text
        args = parse_arguments()
        
        # Validate and prepare environment
        base_folder = validate_and_setup_environment(args)
        
        # Determine operating mode
        mode = determine_mode(base_folder, args.mode)
        log_and_print("mode", f"Operating in {mode.upper()} mode")
        
        # Load and validate email content
        email_content = load_and_validate_email_content(base_folder, mode, args.dry_run)
        
        # Show initial summary
        show_initial_summary(email_content, mode, args)
        
        # Process recipients based on mode
        if mode == "single":
            process_single_mode(base_folder, email_content, args)
        elif mode == "multi":
            process_multi_mode(base_folder, email_content, args)
        else:
            raise ValueError(f"Invalid mode: {mode}")
        
        log_and_print("success", f"NotifyBot {mode.upper()} MODE execution completed successfully")
        
    except MissingRequiredFilesError as e:
        log_and_print("error", f"Missing files: {e}")
        sys.exit(1)
    except ValueError as e:
        log_and_print("error", f"Configuration error: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        log_and_print("warning", "Operation interrupted by user")
        sys.exit(1)
    except Exception as e:
        log_and_print("error", f"Unexpected error: {e}")
        log_and_print("error", f"Traceback: {traceback.format_exc()}")
        sys.exit(1)


def parse_arguments():
    """Parse and validate command line arguments"""
    inventory_fields_help = get_inventory_fields_for_help()
    
    parser = argparse.ArgumentParser(
        description="Send batch emails with single/multi mode support and signature.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
EXAMPLES:
  # Single mode with dry-run
  python notifybot.py --base-folder campaign1 --dry-run
  
  # Multi mode with custom batch size
  python notifybot.py --base-folder campaign2 --mode multi --batch-size 100
  
  # Force send without confirmation
  python notifybot.py --base-folder campaign3 --force

AVAILABLE FIELDS:
{inventory_fields_help}
        """
    )
    
    parser.add_argument(
        "--base-folder", 
        required=True, 
        metavar="BASE_FOLDER",
        help="Base folder name inside /notifybot/basefolder/ [REQUIRED]"
    )
    parser.add_argument(
        "--mode", 
        choices=['single', 'multi'], 
        help="Force mode: 'single' or 'multi' (overrides mode.txt)"
    )
    parser.add_argument(
        "--dry-run", 
        action="store_true", 
        help="Send emails only to approvers with DRAFT prefix"
    )
    parser.add_argument(
        "--force", 
        action="store_true", 
        help="Skip confirmation prompt"
    )
    parser.add_argument(
        "--batch-size", 
        type=int, 
        default=500, 
        help="Number of emails per batch (default: 500)"
    )
    parser.add_argument(
        "--delay", 
        type=float, 
        default=5.0, 
        help="Delay in seconds between batches (default: 5.0)"
    )
    
    args = parser.parse_args()
    
    # Validate arguments
    if args.batch_size <= 0:
        raise ValueError("Batch size must be positive")
    if args.delay < 0:
        raise ValueError("Delay cannot be negative")
    
    return args


def validate_and_setup_environment(args):
    """Validate base folder and setup environment"""
    try:
        base_folder = validate_base_folder(args.base_folder)
        log_and_print("info", f"Using base folder: {base_folder}")
        return base_folder
    except Exception as e:
        raise ValueError(f"Invalid base folder '{args.base_folder}': {e}")


def load_and_validate_email_content(base_folder, mode, dry_run):
    """Load and validate all email content and configuration"""
    # Check required files based on mode
    required_files = ["subject.txt", "body.html", "from.txt", "approver.txt"]
    check_required_files(base_folder, required_files, dry_run, mode)
    
    # Read core email content
    email_content = {
        'subject': read_file(base_folder / "subject.txt"),
        'body_html': read_file(base_folder / "body.html"),
        'from_address': read_file(base_folder / "from.txt"),
        'signature_html': read_signature()
    }
    
    # Validate essential content
    validation_errors = []
    if not email_content['subject']:
        validation_errors.append("Subject is empty")
    if not email_content['body_html']:
        validation_errors.append("Body HTML is empty")
    if not email_content['from_address'] or not is_valid_email(email_content['from_address']):
        validation_errors.append(f"Invalid from address: {email_content['from_address']}")
    
    if validation_errors:
        raise ValueError("; ".join(validation_errors))
    
    # Combine body and signature
    email_content['final_body_html'] = combine_body_and_signature(
        email_content['body_html'], 
        email_content['signature_html']
    )
    
    # Check attachments
    email_content['attachment_folder'] = validate_attachments(base_folder)
    
    return email_content


def validate_attachments(base_folder):
    """Validate attachment folder and return path or None"""
    attachment_folder = base_folder / "attachment"
    
    if attachment_folder.exists():
        attachment_count = len([f for f in attachment_folder.iterdir() if f.is_file()])
        if attachment_count > 0:
            log_and_print("info", f"Found {attachment_count} attachment(s)")
            return attachment_folder
        else:
            log_and_print("info", "Attachment folder exists but is empty")
    else:
        log_and_print("info", "No attachment folder found")
    
    return None


def show_initial_summary(email_content, mode, args):
    """Show initial email configuration summary"""
    log_and_print("info", "=" * 50)
    log_and_print("info", "EMAIL CONFIGURATION SUMMARY")
    log_and_print("info", "=" * 50)
    log_and_print("info", f"Mode: {mode.upper()}")
    log_and_print("info", f"From: {email_content['from_address']}")
    log_and_print("info", f"Subject: {email_content['subject']}")
    
    if email_content['signature_html']:
        log_and_print("info", f"Signature: Loaded ({len(email_content['signature_html'])} characters)")
    
    if email_content['attachment_folder']:
        attachments = [f.name for f in email_content['attachment_folder'].iterdir() if f.is_file()]
        log_and_print("info", f"Attachments: {len(attachments)} files")
    
    if args.dry_run:
        log_and_print("draft", "DRY-RUN MODE: Will send to approvers only")
    
    log_and_print("info", f"Batch size: {args.batch_size}")
    log_and_print("info", f"Delay: {args.delay}s")
    log_and_print("info", "=" * 50)


def process_single_mode(base_folder, email_content, args):
    """Process single mode email campaign"""
    log_and_print("processing", "Processing SINGLE MODE campaign...")
    
    # Get recipients
    (final_recipients, final_cc_recipients, final_bcc_recipients, 
     original_recipients_count, original_cc_count, original_bcc_count) = get_recipients_for_single_mode(
        base_folder, args.dry_run
    )
    
    # Show campaign summary
    show_single_mode_summary(
        final_recipients, final_cc_recipients, final_bcc_recipients,
        original_recipients_count, original_cc_count, original_bcc_count,
        email_content, args
    )
    
    # Get confirmation
    if not args.force and not get_user_confirmation():
        log_and_print("info", "Email sending aborted by user")
        sys.exit(0)
    
    # Send emails
    send_single_mode_emails(
        final_recipients, 
        email_content['subject'], 
        email_content['final_body_html'],
        email_content['from_address'], 
        args.batch_size, 
        dry_run=args.dry_run, 
        delay=args.delay,
        attachment_folder=email_content['attachment_folder'],
        original_recipients_count=original_recipients_count,
        base_folder=base_folder,
        cc_recipients=final_cc_recipients,
        bcc_recipients=final_bcc_recipients,
        original_cc_count=original_cc_count,
        original_bcc_count=original_bcc_count
    )


def process_multi_mode(base_folder, email_content, args):
    """Process multi mode email campaign"""
    log_and_print("processing", "Processing MULTI MODE campaign...")
    
    # Get email configurations
    (email_configs, final_cc_recipients, final_bcc_recipients, 
     total_original_recipients_count, original_cc_count, original_bcc_count) = get_recipients_for_multi_mode(
        base_folder, args.dry_run
    )
    
    # Show campaign summary
    show_multi_mode_summary(
        email_configs, final_cc_recipients, final_bcc_recipients,
        total_original_recipients_count, original_cc_count, original_bcc_count,
        email_content, args
    )
    
    # Get confirmation
    if not args.force and not get_user_confirmation():
        log_and_print("info", "Email sending aborted by user")
        sys.exit(0)
    
    # Send emails
    send_multi_mode_emails(
        email_configs,
        email_content['subject'],
        email_content['final_body_html'],
        email_content['from_address'],
        dry_run=args.dry_run,
        delay=args.delay,
        attachment_folder=email_content['attachment_folder'],
        base_folder=base_folder,
        cc_recipients=final_cc_recipients,
        bcc_recipients=final_bcc_recipients,
        original_cc_count=original_cc_count,
        original_bcc_count=original_bcc_count,
        batch_size=args.batch_size
    )


def show_single_mode_summary(final_recipients, final_cc_recipients, final_bcc_recipients,
                           original_recipients_count, original_cc_count, original_bcc_count,
                           email_content, args):
    """Show single mode campaign summary"""
    log_and_print("confirmation", "SINGLE MODE Campaign Summary:")
    log_and_print("confirmation", f"From: {email_content['from_address']}")
    log_and_print("confirmation", f"Subject: {email_content['subject']}")
    
    if email_content['signature_html']:
        log_and_print("confirmation", f"Signature: Included ({len(email_content['signature_html'])} chars)")
    
    if args.dry_run:
        total_original = original_recipients_count + original_cc_count + original_bcc_count
        log_and_print("confirmation", f"Mode: DRY-RUN (DRAFT to approvers)")
        log_and_print("confirmation", f"Draft recipients: {len(final_recipients)} approver(s)")
        log_and_print("confirmation", f"Original campaign targets: {total_original} recipients")
        log_and_print("confirmation", f"  ‚îî‚îÄ TO: {original_recipients_count}, CC: {original_cc_count}, BCC: {original_bcc_count}")
    else:
        total_live = len(final_recipients) + len(final_cc_recipients) + len(final_bcc_recipients)
        log_and_print("confirmation", f"Mode: LIVE")
        log_and_print("confirmation", f"Total recipients: {total_live}")
        log_and_print("confirmation", f"  ‚îî‚îÄ TO: {len(final_recipients)}, CC: {len(final_cc_recipients)}, BCC: {len(final_bcc_recipients)}")
        
        if total_live > args.batch_size:
            batches = (total_live + args.batch_size - 1) // args.batch_size
            log_and_print("confirmation", f"Batching: {batches} batch(es) of {args.batch_size} max")


def show_multi_mode_summary(email_configs, final_cc_recipients, final_bcc_recipients,
                          total_original_recipients_count, original_cc_count, original_bcc_count,
                          email_content, args):
    """Show multi mode campaign summary"""
    log_and_print("confirmation", "MULTI MODE Campaign Summary:")
    log_and_print("confirmation", f"From: {email_content['from_address']}")
    log_and_print("confirmation", f"Subject Template: {email_content['subject']}")
    
    if email_content['signature_html']:
        log_and_print("confirmation", f"Signature: Included ({len(email_content['signature_html'])} chars)")
    
    log_and_print("confirmation", f"Individual emails: {len(email_configs)}")
    
    if args.dry_run:
        approver_count = len(email_configs[0]['recipients']) if email_configs else 0
        log_and_print("confirmation", f"Mode: DRY-RUN (DRAFT to approvers)")
        log_and_print("confirmation", f"Will send {len(email_configs)} draft emails to {approver_count} approver(s)")
        log_and_print("confirmation", f"Original campaign breakdown:")
        log_and_print("confirmation", f"  ‚îî‚îÄ Total TO recipients: {total_original_recipients_count}")
        log_and_print("confirmation", f"  ‚îî‚îÄ CC per email: {original_cc_count}")
        log_and_print("confirmation", f"  ‚îî‚îÄ BCC per email: {original_bcc_count}")
        
        # Show sample filters
        show_filter_samples(email_configs, original=True)
    else:
        total_cc_bcc_per_email = len(final_cc_recipients) + len(final_bcc_recipients)
        log_and_print("confirmation", f"Mode: LIVE")
        log_and_print("confirmation", f"Total TO recipients: {total_original_recipients_count}")
        log_and_print("confirmation", f"CC per email: {len(final_cc_recipients)}")
        log_and_print("confirmation", f"BCC per email: {len(final_bcc_recipients)}")
        
        if len(email_configs) > 1 and total_cc_bcc_per_email > 0:
            total_cc_bcc = total_cc_bcc_per_email * len(email_configs)
            log_and_print("confirmation", f"Total CC/BCC emails: {total_cc_bcc}")
        
        # Show sample filters
        show_filter_samples(email_configs, original=False)


def show_filter_samples(email_configs, original=False, max_samples=3):
    """Show sample filter configurations"""
    log_and_print("confirmation", f"Filter examples:")
    
    for i, config in enumerate(email_configs[:max_samples], 1):
        filter_line = config['filter_line']
        
        if original:
            count = config.get('original_recipients_count', 0)
        else:
            count = len(config.get('recipients', []))
        
        # Truncate long filter lines
        display_filter = filter_line[:60] + "..." if len(filter_line) > 60 else filter_line
        log_and_print("confirmation", f"  {i}. {display_filter} ‚Üí {count} recipient(s)")
    
    if len(email_configs) > max_samples:
        remaining_count = len(email_configs) - max_samples
        if original:
            remaining_total = sum(
                config.get('original_recipients_count', 0) 
                for config in email_configs[max_samples:]
            )
        else:
            remaining_total = sum(
                len(config.get('recipients', [])) 
                for config in email_configs[max_samples:]
            )
        log_and_print("confirmation", f"  ... and {remaining_count} more filters ‚Üí {remaining_total} additional recipient(s)")


def get_user_confirmation():
    """Get user confirmation with better prompts"""
    try:
        print()  # Add spacing
        response = input("Do you want to proceed with sending emails? (yes/no): ").strip().lower()
        return response in ['yes', 'y']
    except (KeyboardInterrupt, EOFError):
        print("\nOperation cancelled by user")
        return False


if __name__ == "__main__":
    main()

